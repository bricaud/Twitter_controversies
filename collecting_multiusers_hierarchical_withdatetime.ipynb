{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting the data from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Twython class\n",
    "from twython import Twython\n",
    "import json\n",
    "\n",
    "# Load credentials from json file\n",
    "with open(\"twitter_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file)\n",
    "\n",
    "# Instantiate an object\n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date string = 191205\n"
     ]
    }
   ],
   "source": [
    "#username = 'templivs'\n",
    "#username_list  = ['GilbertCollard','dav_dec','Carbongate','bcassoret',\n",
    "#                  'Electroversenet','thinkfree55', 'KlassLib','sauvonsleclimat']\n",
    "\n",
    "username_list = ['francisrichard','MazdaArtaxerxes','templivs','prontipronto',\n",
    "                'Chabadalala','cocktail2Funk','HopitalC',\n",
    "                'riva_vitale','Remifasol57','AitiDouze']\n",
    "\n",
    "swiss_accounts = ['KlimaschutzCH', 'GrueneCH', 'proclimCH', 'EperonP', 'MathiasTemujin',\n",
    "                  'klimastreik', 'AlimEquitables', 'ProNaturaSuisse', 'vertliberaux', 'Munsterma',\n",
    "                  'bourg_d', 'LesVertsSuisses', 'ClimatSuisse', 'gpsuisse', 'IliasPanchard', 'ATE_Suisse']\n",
    "\n",
    "username_list += swiss_accounts\n",
    "# create the path to save the experiment indexed with a date\n",
    "today = date.today()\n",
    "date_string = today.strftime(\"%y%m%d\")\n",
    "print(\"date string =\", date_string)\n",
    "\n",
    "#date_string = '191128'\n",
    "\n",
    "data_path = 'multiusers' + date_string+ '/'\n",
    "#get_tweets = python_tweets.get_user_timeline(screen_name = username,  \n",
    "#                                           count = 200, include_rts = True)\n",
    "if not os.path.isdir(data_path):\n",
    "    os.mkdir(data_path)\n",
    "    print('Path created:',data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 3 # minimal number of mentions to keep\n",
    "max_day_old = 10 # number max of days in the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting the tweets for the last 10 days.\n",
      "Processing francisrichard\n",
      "Empty tweet list. Processing stopped for user  francisrichard\n",
      "Processing MazdaArtaxerxes\n",
      "First user done. Nb different mentions: 2\n",
      "Using threshold: 3\n",
      "Processing templivs\n",
      "First user done. Nb different mentions: 6\n",
      "Using threshold: 3\n",
      "Processing prontipronto\n",
      "First user done. Nb different mentions: 8\n",
      "Using threshold: 3\n",
      "Processing Chabadalala\n",
      "First user done. Nb different mentions: 131\n",
      "Using threshold: 3\n",
      "Writing 1 tweets in multiusers191205/Actu17_mentions_t3.csv.\n",
      "Empty tweet list. Processing stopped for user  Chabadalala\n",
      "Writing 75 tweets in multiusers191205/Incarcerated_ET_mentions_t3.csv.\n",
      "Writing 48 tweets in multiusers191205/LPLdirect_mentions_t3.csv.\n",
      "Writing 84 tweets in multiusers191205/patrick_edery_mentions_t3.csv.\n",
      "Processing cocktail2Funk\n",
      "First user done. Nb different mentions: 52\n",
      "Using threshold: 3\n",
      "Writing 92 tweets in multiusers191205/Courtoisix_mentions_t3.csv.\n",
      "Writing 94 tweets in multiusers191205/HopitalC_mentions_t3.csv.\n",
      "Writing 160 tweets in multiusers191205/ITanerof_mentions_t3.csv.\n",
      "Writing 10 tweets in multiusers191205/OpChemtrails_mentions_t3.csv.\n",
      "Writing 8 tweets in multiusers191205/prontipronto_mentions_t3.csv.\n",
      "Processing HopitalC\n",
      "First user done. Nb different mentions: 94\n",
      "Using threshold: 3\n",
      "Writing 92 tweets in multiusers191205/Courtoisix_mentions_t3.csv.\n",
      "Writing 122 tweets in multiusers191205/CretinusAlp_mentions_t3.csv.\n",
      "Writing 8 tweets in multiusers191205/Gadolinium_MRI_mentions_t3.csv.\n",
      "Writing 160 tweets in multiusers191205/ITanerof_mentions_t3.csv.\n",
      "Writing 106 tweets in multiusers191205/JeanLNeptune_mentions_t3.csv.\n",
      "Writing 97 tweets in multiusers191205/RaderSerge_mentions_t3.csv.\n",
      "Writing 165 tweets in multiusers191205/Studiodjip11_mentions_t3.csv.\n",
      "Writing 49 tweets in multiusers191205/ThierryGolleau_mentions_t3.csv.\n",
      "Writing 52 tweets in multiusers191205/cocktail2Funk_mentions_t3.csv.\n",
      "Writing 151 tweets in multiusers191205/ivre_ensemble_mentions_t3.csv.\n",
      "Writing 43 tweets in multiusers191205/lilmaouz_mentions_t3.csv.\n",
      "Writing 80 tweets in multiusers191205/paulmuaddib61_mentions_t3.csv.\n",
      "Processing riva_vitale\n",
      "First user done. Nb different mentions: 8\n",
      "Using threshold: 3\n",
      "Writing 10 tweets in multiusers191205/TheOven_lol_mentions_t3.csv.\n",
      "Processing Remifasol57\n",
      "First user done. Nb different mentions: 95\n",
      "Using threshold: 3\n",
      "Empty tweet list. Processing stopped for user  Remifasol57\n",
      "Writing 39 tweets in multiusers191205/AitiDouze_mentions_t3.csv.\n",
      "Empty tweet list. Processing stopped for user  Remifasol57\n",
      "Writing 40 tweets in multiusers191205/Conv_Citoyenne_mentions_t3.csv.\n",
      "Writing 7 tweets in multiusers191205/EnModeMacaron_mentions_t3.csv.\n",
      "Writing 4 tweets in multiusers191205/Etienne_Chouard_mentions_t3.csv.\n",
      "Writing 59 tweets in multiusers191205/HForstinger_mentions_t3.csv.\n",
      "Writing 26 tweets in multiusers191205/LeChienDechaine_mentions_t3.csv.\n",
      "Writing 97 tweets in multiusers191205/RaderSerge_mentions_t3.csv.\n",
      "Processing AitiDouze\n",
      "First user done. Nb different mentions: 39\n",
      "Using threshold: 3\n",
      "Writing 51 tweets in multiusers191205/LePoint_mentions_t3.csv.\n",
      "Writing 77 tweets in multiusers191205/Le_Figaro_mentions_t3.csv.\n",
      "Writing 22 tweets in multiusers191205/sputnik_fr_mentions_t3.csv.\n",
      "Processing KlimaschutzCH\n",
      "First user done. Nb different mentions: 30\n",
      "Using threshold: 3\n",
      "Writing 10 tweets in multiusers191205/greenpeace_ch_mentions_t3.csv.\n",
      "Processing GrueneCH\n",
      "First user done. Nb different mentions: 12\n",
      "Using threshold: 3\n",
      "Processing proclimCH\n",
      "First user done. Nb different mentions: 3\n",
      "Using threshold: 3\n",
      "Processing EperonP\n",
      "First user done. Nb different mentions: 2\n",
      "Using threshold: 3\n",
      "Processing MathiasTemujin\n",
      "Empty tweet list. Processing stopped for user  MathiasTemujin\n",
      "Processing klimastreik\n",
      "First user done. Nb different mentions: 10\n",
      "Using threshold: 3\n",
      "Processing AlimEquitables\n",
      "Empty tweet list. Processing stopped for user  AlimEquitables\n",
      "Processing ProNaturaSuisse\n",
      "First user done. Nb different mentions: 1\n",
      "Using threshold: 3\n",
      "Processing vertliberaux\n",
      "Empty tweet list. Processing stopped for user  vertliberaux\n",
      "Processing Munsterma\n",
      "First user done. Nb different mentions: 79\n",
      "Using threshold: 3\n",
      "Writing 58 tweets in multiusers191205/Bergi02_mentions_t3.csv.\n",
      "Writing 5 tweets in multiusers191205/ParlCH_mentions_t3.csv.\n",
      "Writing 2 tweets in multiusers191205/Sdeleury_mentions_t3.csv.\n",
      "Writing 130 tweets in multiusers191205/buercher_mentions_t3.csv.\n",
      "Writing 1 tweets in multiusers191205/ignaziocassis_mentions_t3.csv.\n",
      "Writing 33 tweets in multiusers191205/letemps_mentions_t3.csv.\n",
      "Writing 10 tweets in multiusers191205/murielballaman_mentions_t3.csv.\n",
      "Writing 132 tweets in multiusers191205/nashtags_mentions_t3.csv.\n",
      "Writing 7 tweets in multiusers191205/pascalineminet_mentions_t3.csv.\n",
      "Writing 111 tweets in multiusers191205/yrochat_mentions_t3.csv.\n",
      "Processing bourg_d\n",
      "First user done. Nb different mentions: 61\n",
      "Using threshold: 3\n",
      "Writing 16 tweets in multiusers191205/DamienCAREME_mentions_t3.csv.\n",
      "Writing 174 tweets in multiusers191205/MaximCombes_mentions_t3.csv.\n",
      "Writing 51 tweets in multiusers191205/delphinebatho_mentions_t3.csv.\n",
      "Writing 29 tweets in multiusers191205/lemondefr_mentions_t3.csv.\n",
      "Processing LesVertsSuisses\n",
      "First user done. Nb different mentions: 3\n",
      "Using threshold: 3\n",
      "Processing ClimatSuisse\n",
      "First user done. Nb different mentions: 9\n",
      "Using threshold: 3\n",
      "Processing gpsuisse\n",
      "First user done. Nb different mentions: 4\n",
      "Using threshold: 3\n",
      "Processing IliasPanchard\n",
      "First user done. Nb different mentions: 12\n",
      "Using threshold: 3\n",
      "Writing 3 tweets in multiusers191205/LesVertsSuisses_mentions_t3.csv.\n",
      "Processing ATE_Suisse\n",
      "Empty tweet list. Processing stopped for user  ATE_Suisse\n"
     ]
    }
   ],
   "source": [
    "users_dic = {'username':[], 'Nb_mentions': [], 'mentions_of_mentions': []}\n",
    "print('Collecting the tweets for the last {} days.'.format(max_day_old))\n",
    "for user in username_list:\n",
    "    nb_mentions, mentions_of_mentions = pysad.create_user_edgelist(python_tweets, data_path, user, thres=thres, max_day_old=max_day_old)\n",
    "    users_dic['username'].append(user)\n",
    "    users_dic['Nb_mentions'].append(nb_mentions)\n",
    "    users_dic['mentions_of_mentions'].append(mentions_of_mentions)\n",
    "users_df = pd.DataFrame(users_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>Nb_mentions</th>\n",
       "      <th>mentions_of_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>francisrichard</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MazdaArtaxerxes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>templivs</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prontipronto</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chabadalala</td>\n",
       "      <td>131</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cocktail2Funk</td>\n",
       "      <td>52</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HopitalC</td>\n",
       "      <td>94</td>\n",
       "      <td>1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>riva_vitale</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Remifasol57</td>\n",
       "      <td>95</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AitiDouze</td>\n",
       "      <td>39</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KlimaschutzCH</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GrueneCH</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>proclimCH</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EperonP</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MathiasTemujin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>klimastreik</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AlimEquitables</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ProNaturaSuisse</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vertliberaux</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Munsterma</td>\n",
       "      <td>79</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bourg_d</td>\n",
       "      <td>61</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LesVertsSuisses</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ClimatSuisse</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpsuisse</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>IliasPanchard</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ATE_Suisse</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           username  Nb_mentions  mentions_of_mentions\n",
       "0    francisrichard            0                     0\n",
       "1   MazdaArtaxerxes            2                     0\n",
       "2          templivs            6                     0\n",
       "3      prontipronto            8                     0\n",
       "4       Chabadalala          131                   208\n",
       "5     cocktail2Funk           52                   364\n",
       "6          HopitalC           94                  1125\n",
       "7       riva_vitale            8                    10\n",
       "8       Remifasol57           95                   272\n",
       "9         AitiDouze           39                   150\n",
       "10    KlimaschutzCH           30                    10\n",
       "11         GrueneCH           12                     0\n",
       "12        proclimCH            3                     0\n",
       "13          EperonP            2                     0\n",
       "14   MathiasTemujin            0                     0\n",
       "15      klimastreik           10                     0\n",
       "16   AlimEquitables            0                     0\n",
       "17  ProNaturaSuisse            1                     0\n",
       "18     vertliberaux            0                     0\n",
       "19        Munsterma           79                   489\n",
       "20          bourg_d           61                   270\n",
       "21  LesVertsSuisses            3                     0\n",
       "22     ClimatSuisse            9                     0\n",
       "23         gpsuisse            4                     0\n",
       "24    IliasPanchard           12                     3\n",
       "25       ATE_Suisse            0                     0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the saved data into an edge table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiusers191205/LPLdirect_mentions_t3.csv with 48 tweets.\n",
      "multiusers191205/JeanLNeptune_mentions_t3.csv with 106 tweets.\n",
      "multiusers191205/RaderSerge_mentions_t3.csv with 97 tweets.\n",
      "multiusers191205/sputnik_fr_mentions_t3.csv with 22 tweets.\n",
      "multiusers191205/yrochat_mentions_t3.csv with 111 tweets.\n",
      "multiusers191205/Courtoisix_mentions_t3.csv with 92 tweets.\n",
      "multiusers191205/DamienCAREME_mentions_t3.csv with 16 tweets.\n",
      "multiusers191205/murielballaman_mentions_t3.csv with 10 tweets.\n",
      "multiusers191205/Actu17_mentions_t3.csv with 1 tweets.\n",
      "multiusers191205/HForstinger_mentions_t3.csv with 59 tweets.\n",
      "multiusers191205/lilmaouz_mentions_t3.csv with 43 tweets.\n",
      "multiusers191205/ivre_ensemble_mentions_t3.csv with 151 tweets.\n",
      "multiusers191205/MaximCombes_mentions_t3.csv with 174 tweets.\n",
      "multiusers191205/cocktail2Funk_mentions_t3.csv with 52 tweets.\n",
      "multiusers191205/EnModeMacaron_mentions_t3.csv with 7 tweets.\n",
      "multiusers191205/Le_Figaro_mentions_t3.csv with 77 tweets.\n",
      "multiusers191205/ParlCH_mentions_t3.csv with 5 tweets.\n",
      "multiusers191205/greenpeace_ch_mentions_t3.csv with 10 tweets.\n",
      "multiusers191205/buercher_mentions_t3.csv with 130 tweets.\n",
      "multiusers191205/Etienne_Chouard_mentions_t3.csv with 4 tweets.\n",
      "multiusers191205/LesVertsSuisses_mentions_t3.csv with 3 tweets.\n",
      "multiusers191205/nashtags_mentions_t3.csv with 132 tweets.\n",
      "multiusers191205/pascalineminet_mentions_t3.csv with 7 tweets.\n",
      "multiusers191205/Sdeleury_mentions_t3.csv with 2 tweets.\n",
      "multiusers191205/Gadolinium_MRI_mentions_t3.csv with 8 tweets.\n",
      "multiusers191205/prontipronto_mentions_t3.csv with 8 tweets.\n",
      "multiusers191205/Studiodjip11_mentions_t3.csv with 165 tweets.\n",
      "multiusers191205/AitiDouze_mentions_t3.csv with 39 tweets.\n",
      "multiusers191205/LePoint_mentions_t3.csv with 51 tweets.\n",
      "multiusers191205/Bergi02_mentions_t3.csv with 58 tweets.\n",
      "multiusers191205/Incarcerated_ET_mentions_t3.csv with 75 tweets.\n",
      "multiusers191205/delphinebatho_mentions_t3.csv with 51 tweets.\n",
      "multiusers191205/paulmuaddib61_mentions_t3.csv with 80 tweets.\n",
      "multiusers191205/LeChienDechaine_mentions_t3.csv with 26 tweets.\n",
      "multiusers191205/TheOven_lol_mentions_t3.csv with 10 tweets.\n",
      "multiusers191205/CretinusAlp_mentions_t3.csv with 122 tweets.\n",
      "multiusers191205/ignaziocassis_mentions_t3.csv with 1 tweets.\n",
      "multiusers191205/ITanerof_mentions_t3.csv with 160 tweets.\n",
      "multiusers191205/lemondefr_mentions_t3.csv with 29 tweets.\n",
      "multiusers191205/OpChemtrails_mentions_t3.csv with 10 tweets.\n",
      "multiusers191205/ThierryGolleau_mentions_t3.csv with 49 tweets.\n",
      "multiusers191205/patrick_edery_mentions_t3.csv with 84 tweets.\n",
      "multiusers191205/HopitalC_mentions_t3.csv with 94 tweets.\n",
      "multiusers191205/letemps_mentions_t3.csv with 33 tweets.\n",
      "multiusers191205/Conv_Citoyenne_mentions_t3.csv with 40 tweets.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "edge_df = pd.DataFrame()\n",
    "for filename in glob.glob(data_path + '*_mentions' +'_t' +str(thres)+ '.csv'):\n",
    "    new_edge_df = pd.read_csv(filename)\n",
    "    print('{} with {} tweets.'.format(filename,len(new_edge_df)))\n",
    "    edge_df = edge_df.append(new_edge_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>mention</th>\n",
       "      <th>weight</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>date</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LPLdirect</td>\n",
       "      <td>AlertesInfos</td>\n",
       "      <td>9</td>\n",
       "      <td>['CSA', 'TPMP', 'Gorafi', 'FactCheck']</td>\n",
       "      <td>['2019-12-02 20:23:06', '2019-12-02 20:22:54',...</td>\n",
       "      <td>['https://twitter.com/LPLdirect/status/1201589...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LPLdirect</td>\n",
       "      <td>AnvCop21</td>\n",
       "      <td>1</td>\n",
       "      <td>['Amazon', 'BlackFriday', 'VendrediNoirPourAma...</td>\n",
       "      <td>['2019-11-28 13:40:09']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>LPLdirect</td>\n",
       "      <td>ClementLanot</td>\n",
       "      <td>2</td>\n",
       "      <td>['Amazon', 'BlackFriday', 'CRS', 'agriculteurs...</td>\n",
       "      <td>['2019-11-29 07:55:44', '2019-11-27 11:58:50']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>LPLdirect</td>\n",
       "      <td>Elysee</td>\n",
       "      <td>1</td>\n",
       "      <td>['hopital', 'ministre', 'sante']</td>\n",
       "      <td>['2019-11-29 20:28:28']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>LPLdirect</td>\n",
       "      <td>EvanosNews</td>\n",
       "      <td>1</td>\n",
       "      <td>['RiodeJaneiro', 'Bresil']</td>\n",
       "      <td>['2019-11-29 20:14:50']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Conv_Citoyenne</td>\n",
       "      <td>debatRFI</td>\n",
       "      <td>6</td>\n",
       "      <td>['CitoyensReporters', 'ConventionCitoyenne', '...</td>\n",
       "      <td>['2019-12-05 11:05:24', '2019-12-04 20:03:18',...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Conv_Citoyenne</td>\n",
       "      <td>franceinter</td>\n",
       "      <td>7</td>\n",
       "      <td>['le79inter', 'ConventionCitoyenne', 'le79inte...</td>\n",
       "      <td>['2019-12-04 11:42:40', '2019-12-04 08:36:04',...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Conv_Citoyenne</td>\n",
       "      <td>gilets_citoyens</td>\n",
       "      <td>4</td>\n",
       "      <td>['le79inter', 'ConventionCitoyenne', 'le79inte...</td>\n",
       "      <td>['2019-12-04 08:36:04', '2019-12-04 08:35:24',...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>Conv_Citoyenne</td>\n",
       "      <td>olivierbost</td>\n",
       "      <td>1</td>\n",
       "      <td>['ConventionCitoyenne', 'climat', 'politique']</td>\n",
       "      <td>['2019-11-26 11:58:00']</td>\n",
       "      <td>['https://www.rtl.fr/actu/politique/conference...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Conv_Citoyenne</td>\n",
       "      <td>thierpech</td>\n",
       "      <td>4</td>\n",
       "      <td>['ConventionCitoyenne', 'ConventionCitoyenne',...</td>\n",
       "      <td>['2019-12-02 21:57:24', '2019-11-29 06:41:03',...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0            user          mention  weight  \\\n",
       "0            0       LPLdirect     AlertesInfos       9   \n",
       "1            1       LPLdirect         AnvCop21       1   \n",
       "6            6       LPLdirect     ClementLanot       2   \n",
       "9            9       LPLdirect           Elysee       1   \n",
       "11          11       LPLdirect       EvanosNews       1   \n",
       "..         ...             ...              ...     ...   \n",
       "29          29  Conv_Citoyenne         debatRFI       6   \n",
       "30          30  Conv_Citoyenne      franceinter       7   \n",
       "31          31  Conv_Citoyenne  gilets_citoyens       4   \n",
       "36          36  Conv_Citoyenne      olivierbost       1   \n",
       "38          38  Conv_Citoyenne        thierpech       4   \n",
       "\n",
       "                                             hashtags  \\\n",
       "0              ['CSA', 'TPMP', 'Gorafi', 'FactCheck']   \n",
       "1   ['Amazon', 'BlackFriday', 'VendrediNoirPourAma...   \n",
       "6   ['Amazon', 'BlackFriday', 'CRS', 'agriculteurs...   \n",
       "9                    ['hopital', 'ministre', 'sante']   \n",
       "11                         ['RiodeJaneiro', 'Bresil']   \n",
       "..                                                ...   \n",
       "29  ['CitoyensReporters', 'ConventionCitoyenne', '...   \n",
       "30  ['le79inter', 'ConventionCitoyenne', 'le79inte...   \n",
       "31  ['le79inter', 'ConventionCitoyenne', 'le79inte...   \n",
       "36     ['ConventionCitoyenne', 'climat', 'politique']   \n",
       "38  ['ConventionCitoyenne', 'ConventionCitoyenne',...   \n",
       "\n",
       "                                                 date  \\\n",
       "0   ['2019-12-02 20:23:06', '2019-12-02 20:22:54',...   \n",
       "1                             ['2019-11-28 13:40:09']   \n",
       "6      ['2019-11-29 07:55:44', '2019-11-27 11:58:50']   \n",
       "9                             ['2019-11-29 20:28:28']   \n",
       "11                            ['2019-11-29 20:14:50']   \n",
       "..                                                ...   \n",
       "29  ['2019-12-05 11:05:24', '2019-12-04 20:03:18',...   \n",
       "30  ['2019-12-04 11:42:40', '2019-12-04 08:36:04',...   \n",
       "31  ['2019-12-04 08:36:04', '2019-12-04 08:35:24',...   \n",
       "36                            ['2019-11-26 11:58:00']   \n",
       "38  ['2019-12-02 21:57:24', '2019-11-29 06:41:03',...   \n",
       "\n",
       "                                                 urls  \n",
       "0   ['https://twitter.com/LPLdirect/status/1201589...  \n",
       "1                                                  []  \n",
       "6                                                  []  \n",
       "9                                                  []  \n",
       "11                                                 []  \n",
       "..                                                ...  \n",
       "29                                                 []  \n",
       "30                                                 []  \n",
       "31                                                 []  \n",
       "36  ['https://www.rtl.fr/actu/politique/conference...  \n",
       "38                                                 []  \n",
       "\n",
       "[434 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display edges with number of hashtags >1\n",
    "edge_df[edge_df['hashtags'].apply(lambda x : len(x.split()))>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>mention</th>\n",
       "      <th>weight</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>date</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, user, mention, weight, hashtags, date, urls]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df[edge_df['user'] == edge_df['mention']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "\n",
    "def graph_from_edgeslist(edge_df,degree_min):\n",
    "    print('Creating the graph fro th edge list')\n",
    "    G = nx.from_pandas_edgelist(edge_df,source='user',target='mention', edge_attr=['weight','hashtags','date','urls'])\n",
    "    print('Nb of nodes:',G.number_of_nodes())\n",
    "    # Drop\n",
    "    remove = [node for node,degree in dict(G.degree()).items() if degree < degree_min]\n",
    "    G.remove_nodes_from(remove)\n",
    "    print('Nb of nodes after removing less connected nodes:',G.number_of_nodes())\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the graph fro th edge list\n",
      "Nb of nodes: 2120\n",
      "Nb of nodes after removing less connected nodes: 117\n",
      "removed 3 isolated nodes.\n"
     ]
    }
   ],
   "source": [
    "DEGREE_MIN = 3 # Minimal number of connections in the graph\n",
    "\n",
    "G = graph_from_edgeslist(edge_df,DEGREE_MIN)\n",
    "isolates = list(nx.isolates(G))\n",
    "G.remove_nodes_from(isolates)\n",
    "print('removed {} isolated nodes.'.format(len(isolates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.is_directed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of partitions: 8\n"
     ]
    }
   ],
   "source": [
    "#first compute the best partition\n",
    "partition = community.best_partition(G)\n",
    "nx.set_node_attributes(G,partition,name='community')\n",
    "nb_partitions = max(partition.values())+1\n",
    "print('Nb of partitions:',nb_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname = 'multiusersgraph'\n",
    "#graphname = 'GBRgraph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote multiusers191205/multiusersgraph_t3_graph.gexf\n"
     ]
    }
   ],
   "source": [
    "# Save the graph\n",
    "graphfilename = data_path + graphname + '_t' + str(thres) +'_graph.gexf'\n",
    "nx.write_gexf(G,graphfilename)\n",
    "print('Wrote',graphfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tree graph\n",
    "Skip this section if you do not need to build a hierarchical tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path_of_pyhierarchy_module = '/home/benjamin/Documents/EPFL/Research/hierarchy'\n",
    "path_of_paris_module = '/home/benjamin/Documents/EPFL/Research/hierarchy/paris'\n",
    "\n",
    "sys.path.append(path_of_pyhierarchy_module)\n",
    "sys.path.append(path_of_paris_module)\n",
    "import pyhierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(pyhierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pyhierarchy.create_hierarchy(G)\n",
    "node_list = list(G.nodes())\n",
    "Gtree = pyhierarchy.dendro2graph(D,G,node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname = 'multiusersTreeGraph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the graph\n",
    "graphfilename = data_path + graphname + '_t' + str(thres) +'_graph.gexf'\n",
    "nx.write_gexf(Gtree,graphfilename)\n",
    "print('Wrote',graphfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gtree[2841][2842]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n1,n2,data in Gtree.edges(data=True):\n",
    "    print(data['weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtags, dates and urls\n",
    "Hashtags, dates and urls are on the edges of the network.\n",
    "We can get the most common hashtags within a community and also betwenn communities using the edges that connect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast # convert string to list\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the hashtags for each community and inter-communities\n",
    "tags_dic = {}\n",
    "dates_dic = {}\n",
    "url_dic = {}\n",
    "for node1,node2,data in G.edges(data=True):\n",
    "    if node1 == node2:\n",
    "        print('Self edge',node1)\n",
    "    n1_com = G.nodes[node1]['community']\n",
    "    n2_com = G.nodes[node2]['community']\n",
    "    new_key = str(n1_com) + '-' + str(n2_com) # intra / inter community code\n",
    "    # Convert string to list\n",
    "    x = ast.literal_eval(data['hashtags'])\n",
    "    d = ast.literal_eval(data['date'])\n",
    "    u = ast.literal_eval(data['urls'])\n",
    "    keywords = [n.strip() for n in x]\n",
    "    date_list = [n.strip() for n in d]\n",
    "    urls = [n.strip() for n in u]\n",
    "    if new_key not in tags_dic:\n",
    "        tags_dic[new_key] = keywords\n",
    "        dates_dic[new_key] = date_list\n",
    "        url_dic[new_key] = urls\n",
    "    else:\n",
    "        tags_dic[new_key] += keywords \n",
    "        dates_dic[new_key] += date_list\n",
    "        url_dic[new_key] += urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the most common hashtags in communities and inter communities\n",
    "#for key in tags_dic:\n",
    "#    most_common = Counter(tags_dic[key]).most_common(5)\n",
    "#    print(key)\n",
    "#    print(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meantime(date_list):\n",
    "    d_list = [ datetime.datetime.strptime(dt,'%Y-%m-%d %H:%M:%S') for dt in date_list]\n",
    "    second_list = [x.timestamp() for x in d_list]\n",
    "    meand = np.mean(second_list)\n",
    "    stdd = np.std(second_list)\n",
    "    return datetime.datetime.fromtimestamp(meand),datetime.timedelta(seconds=stdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a table with time and hashtags for each community\n",
    "comm_list = []\n",
    "for key in np.arange(nb_partitions):\n",
    "    keykey = str(key)+ '-' +str(key)\n",
    "    most_common = Counter(tags_dic[keykey]).most_common(5)\n",
    "    meandate,stddate = compute_meantime(dates_dic[keykey])\n",
    "    #print('Community',key)\n",
    "    #print(most_common)\n",
    "    #print('Average date: {} and std deviation: {} days'.format(meandate.date(),stddate.days))\n",
    "    comm_dic = {'Community':key, 'Average date':meandate.date(), 'Deviation (days)':stddate.days}\n",
    "    for htag_nb in range(5): # filling the table with the hashtags\n",
    "        if htag_nb < len(most_common):\n",
    "            comm_dic['hashtag'+str(htag_nb)] = most_common[htag_nb][0]\n",
    "        else:\n",
    "            comm_dic['hashtag'+str(htag_nb)] = ''\n",
    "    comm_list.append(comm_dic)\n",
    "community_table = pd.DataFrame(comm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Community</th>\n",
       "      <th>Average date</th>\n",
       "      <th>Deviation (days)</th>\n",
       "      <th>hashtag0</th>\n",
       "      <th>hashtag1</th>\n",
       "      <th>hashtag2</th>\n",
       "      <th>hashtag3</th>\n",
       "      <th>hashtag4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>3</td>\n",
       "      <td>Macron</td>\n",
       "      <td>NouvelOrdreMondial</td>\n",
       "      <td>Stopmensonges</td>\n",
       "      <td>reformedesretraites</td>\n",
       "      <td>ReformeRetraites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>2</td>\n",
       "      <td>GreveGenerale</td>\n",
       "      <td>GrèveDu5Décembre</td>\n",
       "      <td>DeutscheBank</td>\n",
       "      <td>Voiture_Electrique</td>\n",
       "      <td>Macron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-12-05</td>\n",
       "      <td>0</td>\n",
       "      <td>greve5decembre</td>\n",
       "      <td>GreveGenerale</td>\n",
       "      <td>grevedu5decembre</td>\n",
       "      <td>RetraitePourTous</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>FranceCatholique</td>\n",
       "      <td>RepubliqueJudaique</td>\n",
       "      <td>Antisemitisme</td>\n",
       "      <td>5decembre2019</td>\n",
       "      <td>ARPAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2</td>\n",
       "      <td>TheUnveiling</td>\n",
       "      <td>Oligarchie</td>\n",
       "      <td>ScandaledEtat</td>\n",
       "      <td>TNT</td>\n",
       "      <td>Magouilles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>2</td>\n",
       "      <td>ConventionCitoyenne</td>\n",
       "      <td>climat</td>\n",
       "      <td>le79inter</td>\n",
       "      <td>COP</td>\n",
       "      <td>COP25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2</td>\n",
       "      <td>EF2019</td>\n",
       "      <td>imagine2019</td>\n",
       "      <td>générations</td>\n",
       "      <td>InfoLecteur</td>\n",
       "      <td>BlackFriday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2</td>\n",
       "      <td>opcaf</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Community Average date  Deviation (days)             hashtag0  \\\n",
       "0          0   2019-12-01                 3               Macron   \n",
       "1          1   2019-12-03                 2        GreveGenerale   \n",
       "2          2   2019-12-05                 0       greve5decembre   \n",
       "3          3   2019-12-01                 1     FranceCatholique   \n",
       "4          4   2019-12-01                 2         TheUnveiling   \n",
       "5          5   2019-12-02                 2  ConventionCitoyenne   \n",
       "6          6   2019-12-01                 2               EF2019   \n",
       "7          7   2019-11-30                 2                opcaf   \n",
       "\n",
       "             hashtag1          hashtag2             hashtag3          hashtag4  \n",
       "0  NouvelOrdreMondial     Stopmensonges  reformedesretraites  ReformeRetraites  \n",
       "1    GrèveDu5Décembre      DeutscheBank   Voiture_Electrique            Macron  \n",
       "2       GreveGenerale  grevedu5decembre     RetraitePourTous             Paris  \n",
       "3  RepubliqueJudaique     Antisemitisme        5decembre2019             ARPAC  \n",
       "4          Oligarchie     ScandaledEtat                  TNT        Magouilles  \n",
       "5              climat         le79inter                  COP             COP25  \n",
       "6         imagine2019       générations          InfoLecteur       BlackFriday  \n",
       "7                                                                               "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with the url of each cluster and inter-clusters\n",
    "urltocomm = []\n",
    "for key in url_dic:\n",
    "    for url in url_dic[key]:\n",
    "        urltocomm.append([url,key,1])\n",
    "url_table = pd.DataFrame(urltocomm, columns=['url','Community','Occurence'])\n",
    "url_table = url_table.groupby(['url','Community']).agg(Occurence=('Occurence',sum))\n",
    "url_table = url_table.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all bit.ly url by the correct one\n",
    "import requests\n",
    "\n",
    "session = requests.Session()  # so connections are recycled\n",
    "\n",
    "for index, row in url_table.iterrows():\n",
    "    url = row['url']\n",
    "    if 'bit.ly' in url:\n",
    "        resp = session.head(url, allow_redirects=True)\n",
    "        url_table.loc[index,'url'] = resp.url\n",
    "        #print(resp.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the references to twitter web site\n",
    "twitterrowindices = url_table[url_table['url'].str.contains('twitter.com')].index\n",
    "filtered_url_table = url_table.drop(twitterrowindices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the intra community links\n",
    "dropindices = []\n",
    "for index, row in filtered_url_table.iterrows():\n",
    "    if row['Community'][0] != row['Community'][-1]:\n",
    "        dropindices.append(index)\n",
    "    else: # modify the entry\n",
    "        filtered_url_table.loc[index,'Community'] = row['Community'][0]\n",
    "filtered_url_table = filtered_url_table.drop(dropindices)\n",
    "filtered_url_table.reset_index(inplace=True)\n",
    "filtered_url_table.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort users by community and save in a excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort users by community and store their node degree (importance)\n",
    "community_nodes = {}\n",
    "for node,data in G.nodes(data=True):\n",
    "    community_nb = data['community']\n",
    "    if  community_nb not in community_nodes:\n",
    "        community_nodes[community_nb] = [(node, G.degree(node))]\n",
    "    else:\n",
    "        community_nodes[community_nb].append((node, G.degree(node)))\n",
    "\n",
    "ddf = pd.DataFrame(community_nodes[c_idx],columns=['User','Degree'])\n",
    "\n",
    "# Display the exmaple of community c_idx\n",
    "#c_idx = 0\n",
    "#print('list of most connected users in community',c_idx)\n",
    "#ddf.sort_values(by='Degree',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to an excel file\n",
    "with pd.ExcelWriter(data_path + 'graph_infos.xlsx') as writer:\n",
    "    for community_nb in community_nodes:\n",
    "        ddf = pd.DataFrame(community_nodes[community_nb],columns=['User','Degree'])\n",
    "        ddf = ddf.sort_values(by='Degree',ascending=False)#.head(20)\n",
    "        ddf.to_excel(writer, sheet_name='Community_' + str(community_nb),index=False)\n",
    "    community_table.to_excel(writer, sheet_name='Hashtags',index=False)\n",
    "    users_df.to_excel(writer, sheet_name='Initial_users_details',index=False)\n",
    "    filtered_url_table.to_excel(writer, sheet_name='List_of_urls',index=False)\n",
    "    # Set the column width\n",
    "    column_width = 25\n",
    "    for sheet in writer.sheets: \n",
    "        worksheet = writer.sheets[sheet]\n",
    "        for col in ['A','B','C','D','E','F','G','H']:\n",
    "            worksheet.column_dimensions[col].width = column_width\n",
    "    writer.sheets['List_of_urls'].column_dimensions['A'].width = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
