{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Twython class\n",
    "from twython import Twython\n",
    "import json\n",
    "\n",
    "# Load credentials from json file\n",
    "with open(\"twitter_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file)\n",
    "\n",
    "# Instantiate an object\n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#username = 'templivs'\n",
    "username_list  = ['GilbertCollard','dav_dec','Carbongate','bcassoret',\n",
    "                  'Electroversenet','thinkfree55', 'KlassLib','sauvonsleclimat']\n",
    "data_path = 'multiusers/'\n",
    "#get_tweets = python_tweets.get_user_timeline(screen_name = username,  \n",
    "#                                           count = 200, include_rts = True)\n",
    "if not os.path.isdir(data_path):\n",
    "    os.mkdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_retweet_info(tweet_dic,raw_retweet):\n",
    "    tweet_dic['retweeted_from'].append(raw_retweet['user']['screen_name'])\n",
    "    if raw_retweet['truncated']:\n",
    "        full_text = raw_retweet['extended_tweet']['full_text']\n",
    "    else:\n",
    "        full_text = raw_retweet['full_text']\n",
    "    return tweet_dic, full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_tweets(tweet_handle, username,count=200):\n",
    "    # Collect tweets\n",
    "    tweets_dic = {'user': [], 'date': [], 'text': [], 'favorite_count': [], 'retweet_count': [],\n",
    "        'user_mentions': [], 'urls': [], 'hashtags': [], 'geo': [], 'retweeted_from': []}\n",
    "\n",
    "    for raw_tweet in tweet_handle.get_user_timeline(screen_name = username,  \n",
    "                                           count = count, include_rts = True, tweet_mode='extended'):\n",
    "        # Meta data\n",
    "        tweets_dic['user'].append(raw_tweet['user']['screen_name'])\n",
    "        ts = time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(raw_tweet['created_at'],'%a %b %d %H:%M:%S +0000 %Y'))\n",
    "        tweets_dic['date'].append(ts)\n",
    "        tweets_dic['favorite_count'].append(raw_tweet['favorite_count'])\n",
    "        tweets_dic['retweet_count'].append(raw_tweet['retweet_count'])    \n",
    "        tweets_dic['user_mentions'].append([user['screen_name'] for user in raw_tweet['entities']['user_mentions']])\n",
    "        tweets_dic['urls'].append([url['url'] for url in raw_tweet['entities']['urls']])\n",
    "        tweets_dic['hashtags'].append([htg['text'] for htg in raw_tweet['entities']['hashtags']])\n",
    "        #if raw_tweet['entities']['hashtags']:\n",
    "        #    print([htg['text'] for htg in raw_tweet['entities']['hashtags']])\n",
    "        tweets_dic['geo'].append(raw_tweet['geo'])\n",
    "        \n",
    "        # Handle text and retweet data\n",
    "        if raw_tweet['truncated']:\n",
    "            full_text = raw_tweet['extended_tweet']['full_text']\n",
    "        else:\n",
    "            full_text = raw_tweet['full_text']    \n",
    "        if 'retweeted_status' in raw_tweet:\n",
    "            tweets_dic, full_text = fill_retweet_info(tweets_dic,raw_tweet['retweeted_status'])\n",
    "        else:\n",
    "            tweets_dic['retweeted_from'].append(None)\n",
    "        tweets_dic['text'].append(full_text)\n",
    "    return tweets_dic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mentions_edges(tweet_df):\n",
    "    mention_df = pd.DataFrame(columns=['user','mention','weight'])\n",
    "    row_list = []\n",
    "    for idx,tweet in tweet_df.iterrows():\n",
    "        user = tweet['user']\n",
    "        mentions = tweet['user_mentions']\n",
    "        hashtags = tweet['hashtags']\n",
    "        for m in mentions:\n",
    "            row_list.append({'user':user,'mention': m, 'weight': 1, 'hashtags': hashtags})\n",
    "    mention_df = pd.DataFrame(row_list)\n",
    "    if mention_df.empty:\n",
    "        return None\n",
    "    # this agg only works with pandas version >= 0.25\n",
    "    mention_grouped = mention_df.groupby(['user','mention']).agg(weight=('weight',sum),\n",
    "                                                                 hashtags=('hashtags', sum))#lambda x: list(x)))    \n",
    "    mention_g_list = mention_df.groupby(['user','mention'])['hashtags'].apply(list)\n",
    "    mention_grouped.reset_index(level=['user', 'mention'], inplace=True)\n",
    "    return mention_grouped,mention_g_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_user_mention(username,python_tweets,data_path):\n",
    "    tweets_dic = get_user_tweets(python_tweets,username,count=200)\n",
    "    tweet_df = pd.DataFrame(tweets_dic)\n",
    "    mention_grouped,mention_g_list = get_mentions_edges(tweet_df)\n",
    "    return mention_grouped, mention_g_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_edgelist(python_tweets, data_path, username, thres=3):\n",
    "    # initial user\n",
    "    print('Processing',username)\n",
    "    try:\n",
    "        mention_grouped,mgl = collect_user_mention(username,python_tweets,data_path)\n",
    "    except:\n",
    "        print('exception catched on user {} !!!!!!!!!!!!'.format(username))\n",
    "        return\n",
    "    mention_grouped.to_csv(data_path + username + '_mentions.csv')\n",
    "    print('First user done')\n",
    "\n",
    "    # Threshold for number of mentions\n",
    "    print('Using threshold:',thres)\n",
    "\n",
    "    for idx,row in mention_grouped.iterrows():\n",
    "        print('processing mention',idx)\n",
    "        mention_name = row['mention']\n",
    "        if row['weight'] < thres:\n",
    "            continue\n",
    "        try:\n",
    "            mention_grouped,mgl = collect_user_mention(mention_name,python_tweets,data_path)\n",
    "        except:\n",
    "            print('exception catched on user {} !!!!!!!!!!!!'.format(username))\n",
    "            continue\n",
    "        if mention_grouped is not None:\n",
    "            mentionfilename = data_path + mention_name + '_mentions' +'_t' +str(thres)+'.csv'\n",
    "            print('Writing',mentionfilename)\n",
    "            mention_grouped.to_csv(mentionfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path = 'GBR_data/'\n",
    "#username_list = ['GBR_Data']\n",
    "thres = 3\n",
    "for user in username_list:\n",
    "    create_user_edgelist(python_tweets, data_path, user, thres=thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "edge_df = pd.DataFrame()\n",
    "for filename in glob.glob(data_path + '*_mentions' +'_t' +str(thres)+ '.csv'):\n",
    "    print(filename)\n",
    "    new_edge_df = pd.read_csv(filename)\n",
    "    edge_df = edge_df.append(new_edge_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df[edge_df['hashtags'].apply(lambda x : len(x.split()))>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.from_pandas_edgelist(edge_df,source='user',target='mention', edge_attr=['weight','hashtags'])\n",
    "print('Nb of nodes:',G.number_of_nodes())\n",
    "# Drop\n",
    "remove = [node for node,degree in dict(G.degree()).items() if degree < 4]\n",
    "G.remove_nodes_from(remove)\n",
    "print('Nb of nodes after removing less connected nodes:',G.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname = 'multiusersgraph'\n",
    "#graphname = 'GBRgraph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the graph\n",
    "graphfilename = data_path + graphname + '_t' + str(thres) +'_graph.gexf'\n",
    "nx.write_gexf(G,graphfilename)\n",
    "print('Wrote',graphfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
