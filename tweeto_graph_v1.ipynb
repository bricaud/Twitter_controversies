{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting the data from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Twython class\n",
    "from twython import Twython\n",
    "import json\n",
    "\n",
    "# Load credentials from json file\n",
    "with open(\"twitter_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file)\n",
    "\n",
    "# Instantiate an object\n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pysad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pysad' from '/home/benjamin/Documents/EPFL/Research/sad/sad_tweets/pysad.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(pysad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_accounts = pysad.initial_accounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['swiss_climate_regular',\n",
       " 'swiss_climate_controversial',\n",
       " 'swiss_immigration',\n",
       " 'french_tech_lesechos']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_accounts.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date string = 20200131\n",
      "Path created: tweetdata/swiss_climate_controversial/20200131/\n",
      "Path created: resultsdata/swiss_climate_controversial/\n",
      "Path created: resultsdata/swiss_climate_controversial/20200131/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "######Choose a category##############    \n",
    "category_name = 'swiss_climate_controversial'\n",
    "#category_name = 'swiss_climate_regular'\n",
    "#category_name = 'french_tech_lesechos'\n",
    "#category_name = 'swiss_immigration'\n",
    "#####################################\n",
    "\n",
    "username_list = init_accounts.accounts(category_name)\n",
    "\n",
    "# create the path to save the experiment indexed with a date\n",
    "today = date.today()\n",
    "date_string = today.strftime(\"%Y%m%d\")\n",
    "print(\"date string =\", date_string)\n",
    "\n",
    "#date_string = '191128'\n",
    "\n",
    "tweet_data_path_list = ['tweetdata', category_name, date_string]\n",
    "results_data_path_list = ['resultsdata', category_name, date_string]\n",
    "#get_tweets = python_tweets.get_user_timeline(screen_name = username,  \n",
    "#         count = 200, include_rts = True)\n",
    "\n",
    "def initialize_folder(path_folder_list):\n",
    "    folder_concat = ''\n",
    "    for folder in path_folder_list[:-1]:\n",
    "        folder_concat += folder + '/'\n",
    "        if not os.path.isdir(folder_concat):\n",
    "            os.mkdir(folder_concat)\n",
    "            print('Path created:',folder_concat)\n",
    "    # Special treatment for the last folder\n",
    "    folder_concat += path_folder_list[-1] + '/'\n",
    "    if not os.path.isdir(folder_concat):\n",
    "        os.mkdir(folder_concat)\n",
    "        print('Path created:',folder_concat)\n",
    "    else:\n",
    "        for f in os.listdir(folder_concat):\n",
    "            os.remove(os.path.join(folder_concat, f))\n",
    "        print('Cleaned path',folder_concat)\n",
    "    return folder_concat\n",
    "\n",
    "tweet_data_path = initialize_folder(tweet_data_path_list)\n",
    "results_data_path = initialize_folder(results_data_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['francisrichard',\n",
       " 'MazdaArtaxerxes',\n",
       " 'templivs',\n",
       " 'prontipronto',\n",
       " 'Chabadalala',\n",
       " 'cocktail2Funk',\n",
       " 'HopitalC',\n",
       " 'riva_vitale',\n",
       " 'Remifasol57',\n",
       " 'AitiDouze',\n",
       " 'QAnonAustria1',\n",
       " 'gotteswerk2411']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mentions = 2 # minimal number of mentions of a user to be followed\n",
    "max_day_old = 7 # number max of days in the past\n",
    "exploration_depth = 2 # mention of mention of mention of ... up to exploration depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold set to 2 mentions.\n",
      "Collecting the tweets for the last 7 days.\n",
      "\n",
      "******* Processing users at 0-hop distance *******\n",
      "Collecting the tweets for the last 7 days.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.26it/s]\n",
      "  0%|          | 0/43 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users with empty tweet list or no mention: ['francisrichard']\n",
      "\n",
      "******* Processing users at 1-hop distance *******\n",
      "Collecting the tweets for the last 7 days.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 33/43 [00:24<00:07,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter API returned error 401 for user PensePetitHans.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:32<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users with empty tweet list or no mention: ['Etienne_Chouard', 'PensePetitHans', 'DebnamCarey']\n",
      "Total number of users collected:\n",
      "236 236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_user_list = pysad.collect_tweets(username_list, tweet_data_path, python_tweets, min_mentions=min_mentions,\n",
    "               max_day_old=max_day_old, exploration_depth=exploration_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_user_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the saved data into an edge table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweetdata/swiss_climate_controversial/20200131/Todesengel1179_mentions_t2.json with 17 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/adcdaily_mentions_t2.json with 8 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/RestitutorOrien_mentions_t2.json with 40 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/AitiDouze_mentions_t2.json with 76 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/cocktail2Funk_mentions_t2.json with 50 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/lovephilosophy_mentions_t2.json with 1 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/FridayForFuture_mentions_t2.json with 13 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/QAnonAustria1_mentions_t2.json with 34 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/MoadabJ_mentions_t2.json with 39 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/EnModeMacaron_mentions_t2.json with 10 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/Conflits_FR_mentions_t2.json with 43 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/ITanerof_mentions_t2.json with 45 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/DavyTmz_mentions_t2.json with 105 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/HopitalC_mentions_t2.json with 32 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/Poulin2012_mentions_t2.json with 75 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/lilmaouz_mentions_t2.json with 53 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/Abdou64533132_mentions_t2.json with 58 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/pierrejovanovic_mentions_t2.json with 101 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/NewstvFrench_mentions_t2.json with 70 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/TenteLacHans_mentions_t2.json with 47 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/CretinusAlp_mentions_t2.json with 47 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/prontipronto_mentions_t2.json with 48 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/PaulMaxit_mentions_t2.json with 4 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/__Carlota_mentions_t2.json with 76 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/gotteswerk2411_mentions_t2.json with 17 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/VQuaschning_mentions_t2.json with 5 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/bundeswehrInfo_mentions_t2.json with 35 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/didier_carette_mentions_t2.json with 19 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/StormIsUponUs_mentions_t2.json with 14 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/rahmstorf_mentions_t2.json with 42 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/Europakonzept_mentions_t2.json with 105 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/thinkfree55_mentions_t2.json with 65 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/Remifasol57_mentions_t2.json with 58 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/Die_Gruenen_mentions_t2.json with 7 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/ivre_ensemble_mentions_t2.json with 61 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/TerliWetter_mentions_t2.json with 75 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/HusoBot_mentions_t2.json with 173 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/A1Telekom_mentions_t2.json with 32 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/Actu17_mentions_t2.json with 1 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/ConflitsFR_mentions_t2.json with 31 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/LevyLoiseau_mentions_t2.json with 103 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/riva_vitale_mentions_t2.json with 44 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/ohboywhatashot_mentions_t2.json with 11 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/LPLdirect_mentions_t2.json with 26 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/templivs_mentions_t2.json with 3 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/Luisamneubauer_mentions_t2.json with 27 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/MazdaArtaxerxes_mentions_t2.json with 6 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/Chabadalala_mentions_t2.json with 82 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/Emonet4_mentions_t2.json with 46 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/Gadolinium_MRI_mentions_t2.json with 10 tweets.\n",
      "tweetdata/swiss_climate_controversial/20200131/HarryoFfm_mentions_t2.json with 59 tweets.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "edge_df = pd.DataFrame()\n",
    "for filename in glob.glob(tweet_data_path + '*_mentions' +'_t' +str(min_mentions)+ '.json'):\n",
    "    new_edge_df = pd.read_json(filename)\n",
    "    print('{} with {} tweets.'.format(filename,len(new_edge_df)))\n",
    "    edge_df = edge_df.append(new_edge_df)\n",
    "edge_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the graph from the edge list\n",
      "Field \"hashtags\" of class <class 'list'> converted to json string\n",
      "Field \"date\" of class <class 'list'> converted to json string\n",
      "Field \"urls\" of class <class 'list'> converted to json string\n",
      "Field \"text\" of class <class 'list'> converted to json string\n",
      "Nb of nodes: 1928\n",
      "Nb of nodes after removing nodes with degree strictly smaller than 2: 231\n",
      "removed 0 isolated nodes.\n"
     ]
    }
   ],
   "source": [
    "DEGREE_MIN = 2 # Minimal number of connections in the graph\n",
    "\n",
    "G = pysad.graph_from_edgeslist(edge_df,DEGREE_MIN)\n",
    "G.name = category_name\n",
    "G.date = date_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community detection and save full graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communities saved on the graph as node attributes.\n",
      "Nb of partitions: 10\n"
     ]
    }
   ],
   "source": [
    "G,clusters = pysad.detect_communities(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote resultsdata/swiss_immigration/20200131/globalgraph_t2_md2_graph.gexf\n"
     ]
    }
   ],
   "source": [
    "# Save the graph\n",
    "import networkx as nx\n",
    "\n",
    "graphname = 'globalgraph'\n",
    "\n",
    "graphfilename = results_data_path + graphname + '_t' + str(min_mentions) + '_md' + str(DEGREE_MIN) +'_graph.gexf'\n",
    "nx.write_gexf(G,graphfilename)\n",
    "#nx.write_yaml(G,graphfilename)\n",
    "#nx.write_pajek(G,graphfilename)\n",
    "#nx.node_link_data(G,graphfilename)\n",
    "print('Wrote',graphfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic processing of all clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_info_dic = {}\n",
    "for c_id in clusters:\n",
    "    cgraph = clusters[c_id]\n",
    "    cgraph = pysad.cluster_attributes(cgraph)\n",
    "    table_dic = pysad.cluster_tables(cgraph)\n",
    "    cluster_filename = results_data_path + 'cluster' + str(c_id)\n",
    "    cluster_info_dic[c_id] = {}\n",
    "    cluster_info_dic[c_id]['info_table'] = table_dic\n",
    "    cluster_info_dic[c_id]['filename'] = cluster_filename    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding global infos\n",
    "# keywords\n",
    "corpus = pysad.get_corpus(cluster_info_dic)\n",
    "keyword_dic = pysad.tfidf(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to resultsdata/swiss_climate_controversial/20200131/cluster0_infos.xlsx\n",
      "Graph saved to resultsdata/swiss_climate_controversial/20200131/cluster0graph.gexf\n",
      "Data saved to resultsdata/swiss_climate_controversial/20200131/cluster1_infos.xlsx\n",
      "Graph saved to resultsdata/swiss_climate_controversial/20200131/cluster1graph.gexf\n",
      "Data saved to resultsdata/swiss_climate_controversial/20200131/cluster2_infos.xlsx\n",
      "Graph saved to resultsdata/swiss_climate_controversial/20200131/cluster2graph.gexf\n",
      "Data saved to resultsdata/swiss_climate_controversial/20200131/cluster3_infos.xlsx\n",
      "Graph saved to resultsdata/swiss_climate_controversial/20200131/cluster3graph.gexf\n",
      "Data saved to resultsdata/swiss_climate_controversial/20200131/cluster4_infos.xlsx\n",
      "Graph saved to resultsdata/swiss_climate_controversial/20200131/cluster4graph.gexf\n",
      "Data saved to resultsdata/swiss_climate_controversial/20200131/cluster5_infos.xlsx\n",
      "Graph saved to resultsdata/swiss_climate_controversial/20200131/cluster5graph.gexf\n",
      "Data saved to resultsdata/swiss_climate_controversial/20200131/cluster6_infos.xlsx\n",
      "Graph saved to resultsdata/swiss_climate_controversial/20200131/cluster6graph.gexf\n",
      "Data saved to resultsdata/swiss_climate_controversial/20200131/cluster7_infos.xlsx\n",
      "Graph saved to resultsdata/swiss_climate_controversial/20200131/cluster7graph.gexf\n",
      "Data saved to resultsdata/swiss_climate_controversial/20200131/cluster8_infos.xlsx\n",
      "Graph saved to resultsdata/swiss_climate_controversial/20200131/cluster8graph.gexf\n",
      "Data saved to resultsdata/swiss_climate_controversial/20200131/cluster9_infos.xlsx\n",
      "Graph saved to resultsdata/swiss_climate_controversial/20200131/cluster9graph.gexf\n"
     ]
    }
   ],
   "source": [
    "# gathering global info\n",
    "# Saving in files\n",
    "for c_id in cluster_info_dic:\n",
    "    info_table = cluster_info_dic[c_id]['info_table']\n",
    "    info_table['keywords'] = keyword_dic[c_id]\n",
    "    pysad.save_excel(info_table,cluster_info_dic[c_id]['filename'] + '_infos.xlsx')\n",
    "    pysad.save_graph(clusters[c_id],cluster_info_dic[c_id]['filename'] + 'graph.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
