{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import json\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting the data from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Twython class\n",
    "from twython import Twython\n",
    "import json\n",
    "\n",
    "# Load credentials from json file\n",
    "with open(\"twitter_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file)\n",
    "\n",
    "# Instantiate an object\n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pysad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pysad' from '/home/benjamin/Documents/EPFL/Research/sad/sad_tweets/pysad.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(pysad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_accounts = pysad.initial_accounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['swiss_climate_regular',\n",
       " 'swiss_climate_controversial',\n",
       " 'swiss_immigration',\n",
       " 'french_tech_lesechos',\n",
       " 'swiss_immigration2',\n",
       " 'debat_burqa']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_accounts.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date string = 20200219\n",
      "Cleaned path tweetdata/swiss_climate_regular/20200219/\n",
      "Cleaned path resultsdata2/swiss_climate_regular/20200219/\n"
     ]
    }
   ],
   "source": [
    "######Choose a category##############    \n",
    "#category_name = 'swiss_climate_controversial'\n",
    "category_name = 'swiss_climate_regular'\n",
    "#category_name = 'french_tech_lesechos'\n",
    "#category_name = 'swiss_immigration'\n",
    "#category_name = 'swiss_immigration2'\n",
    "#category_name = 'debat_burqa'\n",
    "#####################################\n",
    "\n",
    "username_list = init_accounts.accounts(category_name)\n",
    "\n",
    "# create the path to save the experiment indexed with the date of today\n",
    "today = date.today()\n",
    "date_string = today.strftime(\"%Y%m%d\")\n",
    "print(\"date string =\", date_string)\n",
    "\n",
    "tweet_data_path_list = ['tweetdata', category_name, date_string]\n",
    "results_data_path_list = ['resultsdata2', category_name, date_string]\n",
    "\n",
    "# Initialize folders (create or clean them if they exist)\n",
    "tweet_data_path = pysad.initialize_folder(tweet_data_path_list)\n",
    "results_data_path = pysad.initialize_folder(results_data_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KlimaschutzCH',\n",
       " 'GrueneCH',\n",
       " 'proclimCH',\n",
       " 'EperonP',\n",
       " 'MathiasTemujin',\n",
       " 'klimastreik',\n",
       " 'AlimEquitables',\n",
       " 'ProNaturaSuisse',\n",
       " 'vertliberaux',\n",
       " 'Munsterma',\n",
       " 'bourg_d',\n",
       " 'LesVertsSuisses',\n",
       " 'ClimatSuisse',\n",
       " 'gpsuisse',\n",
       " 'IliasPanchard',\n",
       " 'ATE_Suisse']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mentions = 2 # minimal number of mentions of a user to be followed\n",
    "max_day_old = 7 # number max of days in the past\n",
    "exploration_depth = 3 # mention of mention of mention of ... up to exploration depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold set to 2 mentions.\n",
      "Collecting the tweets for the last 7 days.\n",
      "\n",
      "******* Processing users at 0-hop distance *******\n",
      "Collecting the tweets for the last 7 days.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:22<00:00,  1.38s/it]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users with empty tweet list or no mention: ['EperonP', 'AlimEquitables', 'ProNaturaSuisse', 'ATE_Suisse']\n",
      "\n",
      "******* Processing users at 1-hop distance *******\n",
      "Collecting the tweets for the last 7 days.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:14<00:00,  1.06s/it]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users with empty tweet list or no mention: ['CreditSuisse', 'Mercuria']\n",
      "\n",
      "******* Processing users at 2-hop distance *******\n",
      "Collecting the tweets for the last 7 days.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 57/59 [00:48<00:01,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter API returned error 401 for user esmepim.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59/59 [00:50<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users with empty tweet list or no mention: ['Gunvor', 'ConstructPaille', 'LafargeGroup', 'vitolgroup', 'esmepim']\n",
      "Total number of users collected:\n",
      "296 296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_user_list = pysad.collect_tweets(username_list, tweet_data_path, python_tweets, min_mentions=min_mentions,\n",
    "               max_day_old=max_day_old, exploration_depth=exploration_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_user_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Loading the saved data into an edge table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweetdata/swiss_climate_regular/20200219/CamCrosnier_mentions_t2.json with 23 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/dani_graf_mentions_t2.json with 92 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/LesVertsSuisses_mentions_t2.json with 2 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/MathiasTemujin_mentions_t2.json with 5 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/WWFFrance_mentions_t2.json with 47 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/Bouygues_C_mentions_t2.json with 4 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/attac_fr_mentions_t2.json with 122 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/BreakfreeCH_mentions_t2.json with 38 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/oliverlutz1_mentions_t2.json with 33 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/ClimatSuisse_mentions_t2.json with 2 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/XRChambery_mentions_t2.json with 34 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/Fraise_des_bois_mentions_t2.json with 107 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/selectedhearing_mentions_t2.json with 120 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/gnoni_sara_mentions_t2.json with 51 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/Le_Museum_mentions_t2.json with 23 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/Munsterma_mentions_t2.json with 57 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/funambuline_mentions_t2.json with 76 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/vertliberaux_mentions_t2.json with 4 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/MFrauchigerSVP_mentions_t2.json with 501 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/RogerWakeUpNow_mentions_t2.json with 150 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/eric_maechler_mentions_t2.json with 120 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/Francetele_mentions_t2.json with 59 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/Bloom_FR_mentions_t2.json with 35 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/greveduclimat_mentions_t2.json with 128 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/DimplesB_mentions_t2.json with 1 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/peoplevsoil_mentions_t2.json with 131 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/wieselT_mentions_t2.json with 8 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/Glencore_mentions_t2.json with 2 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/bglaettli_mentions_t2.json with 76 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/cframmery_mentions_t2.json with 30 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/xr_lyon_mentions_t2.json with 38 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/WohlgensingerN_mentions_t2.json with 304 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/EmmanuelMacron_mentions_t2.json with 3 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/Vertliberaux_GE_mentions_t2.json with 2 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/Cargill_mentions_t2.json with 1 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/xrFrance_mentions_t2.json with 247 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/ExtinctionR_mentions_t2.json with 125 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/llavocat_mentions_t2.json with 4 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/GrueneCH_mentions_t2.json with 13 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/LaTacfi_mentions_t2.json with 56 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/Trafigura_mentions_t2.json with 3 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/WeAreLDC_mentions_t2.json with 4 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/FabienGrenon_mentions_t2.json with 9 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/josef_lang_mentions_t2.json with 298 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/proclimCH_mentions_t2.json with 1 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/Youth4Climatefr_mentions_t2.json with 36 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/AssociationLesa_mentions_t2.json with 11 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/GroupeBouygues_mentions_t2.json with 40 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/shalf_mentions_t2.json with 102 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/Sorbonne_Univ__mentions_t2.json with 29 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/gpsuisse_mentions_t2.json with 22 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/PartagerCSympa_mentions_t2.json with 27 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/zehavoc_mentions_t2.json with 146 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/XrFranck_mentions_t2.json with 28 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/redrebelbrigade_mentions_t2.json with 4 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/amisdelaterre_mentions_t2.json with 34 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/LCI_mentions_t2.json with 85 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/pierrecannet_mentions_t2.json with 32 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/OsonsCauser_mentions_t2.json with 3 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/simhung_mentions_t2.json with 12 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/FredLeManach_mentions_t2.json with 18 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/KlimaschutzCH_mentions_t2.json with 3 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/celuiqui_mentions_t2.json with 18 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/Reporterre_mentions_t2.json with 59 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/fredericleuba_mentions_t2.json with 25 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/migros_mentions_t2.json with 133 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/IliasPanchard_mentions_t2.json with 17 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/tagesanzeiger_mentions_t2.json with 10 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/klimastreik_mentions_t2.json with 3 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/xrlausanne_mentions_t2.json with 125 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/LaurentNetTweet_mentions_t2.json with 105 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/bourg_d_mentions_t2.json with 138 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/rogerruckstuhl_mentions_t2.json with 69 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/ademe_mentions_t2.json with 50 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/cyberhelvetia_mentions_t2.json with 235 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/ZuercherMarkus_mentions_t2.json with 15 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/TF1_mentions_t2.json with 161 tweets.\n",
      "tweetdata/swiss_climate_regular/20200219/VexinZone109_mentions_t2.json with 378 tweets.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "edge_df = pd.DataFrame()\n",
    "for filename in glob.glob(tweet_data_path + '*_mentions' +'_t' +str(min_mentions)+ '.json'):\n",
    "    new_edge_df = pd.read_json(filename)\n",
    "    print('{} with {} tweets.'.format(filename,len(new_edge_df)))\n",
    "    edge_df = edge_df.append(new_edge_df)\n",
    "edge_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>mention</th>\n",
       "      <th>weight</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>date</th>\n",
       "      <th>urls</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CamCrosnier</td>\n",
       "      <td>paulcng</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-02-19 17:27:36</td>\n",
       "      <td>[]</td>\n",
       "      <td>@paulcng @pilorgetrezzouk @expliciteJA Tristes...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CamCrosnier</td>\n",
       "      <td>pilorgetrezzouk</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-02-19 17:27:36</td>\n",
       "      <td>[]</td>\n",
       "      <td>@paulcng @pilorgetrezzouk @expliciteJA Tristes...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CamCrosnier</td>\n",
       "      <td>expliciteJA</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-02-19 17:27:36</td>\n",
       "      <td>[]</td>\n",
       "      <td>@paulcng @pilorgetrezzouk @expliciteJA Tristes...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CamCrosnier</td>\n",
       "      <td>paulcng</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-02-19 17:11:40</td>\n",
       "      <td>[]</td>\n",
       "      <td>@paulcng @pilorgetrezzouk @expliciteJA ðŸ˜°ðŸ˜± c'es...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CamCrosnier</td>\n",
       "      <td>pilorgetrezzouk</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-02-19 17:11:40</td>\n",
       "      <td>[]</td>\n",
       "      <td>@paulcng @pilorgetrezzouk @expliciteJA ðŸ˜°ðŸ˜± c'es...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5357</th>\n",
       "      <td>VexinZone109</td>\n",
       "      <td>FederationPNR</td>\n",
       "      <td>1</td>\n",
       "      <td>[Zone109, PNRVexin, Yvelines]</td>\n",
       "      <td>2020-02-12 21:08:20</td>\n",
       "      <td>[https://twitter.com/bfmparis/status/117131151...</td>\n",
       "      <td>@MichaelWeber1 @FederationPNR @Elysee @EmmWarg...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5358</th>\n",
       "      <td>VexinZone109</td>\n",
       "      <td>Elysee</td>\n",
       "      <td>1</td>\n",
       "      <td>[Zone109, PNRVexin, Yvelines]</td>\n",
       "      <td>2020-02-12 21:08:20</td>\n",
       "      <td>[https://twitter.com/bfmparis/status/117131151...</td>\n",
       "      <td>@MichaelWeber1 @FederationPNR @Elysee @EmmWarg...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5359</th>\n",
       "      <td>VexinZone109</td>\n",
       "      <td>EmmWargon</td>\n",
       "      <td>1</td>\n",
       "      <td>[Zone109, PNRVexin, Yvelines]</td>\n",
       "      <td>2020-02-12 21:08:20</td>\n",
       "      <td>[https://twitter.com/bfmparis/status/117131151...</td>\n",
       "      <td>@MichaelWeber1 @FederationPNR @Elysee @EmmWarg...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5360</th>\n",
       "      <td>VexinZone109</td>\n",
       "      <td>Elisabeth_Borne</td>\n",
       "      <td>1</td>\n",
       "      <td>[Zone109, PNRVexin, Yvelines]</td>\n",
       "      <td>2020-02-12 21:08:20</td>\n",
       "      <td>[https://twitter.com/bfmparis/status/117131151...</td>\n",
       "      <td>@MichaelWeber1 @FederationPNR @Elysee @EmmWarg...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5361</th>\n",
       "      <td>VexinZone109</td>\n",
       "      <td>EmmanuelMacron</td>\n",
       "      <td>1</td>\n",
       "      <td>[Zone109, PNRVexin, Yvelines]</td>\n",
       "      <td>2020-02-12 21:08:20</td>\n",
       "      <td>[https://twitter.com/bfmparis/status/117131151...</td>\n",
       "      <td>@MichaelWeber1 @FederationPNR @Elysee @EmmWarg...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5362 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              user          mention  weight                       hashtags  \\\n",
       "0      CamCrosnier          paulcng       1                             []   \n",
       "1      CamCrosnier  pilorgetrezzouk       1                             []   \n",
       "2      CamCrosnier      expliciteJA       1                             []   \n",
       "3      CamCrosnier          paulcng       1                             []   \n",
       "4      CamCrosnier  pilorgetrezzouk       1                             []   \n",
       "...            ...              ...     ...                            ...   \n",
       "5357  VexinZone109    FederationPNR       1  [Zone109, PNRVexin, Yvelines]   \n",
       "5358  VexinZone109           Elysee       1  [Zone109, PNRVexin, Yvelines]   \n",
       "5359  VexinZone109        EmmWargon       1  [Zone109, PNRVexin, Yvelines]   \n",
       "5360  VexinZone109  Elisabeth_Borne       1  [Zone109, PNRVexin, Yvelines]   \n",
       "5361  VexinZone109   EmmanuelMacron       1  [Zone109, PNRVexin, Yvelines]   \n",
       "\n",
       "                    date                                               urls  \\\n",
       "0    2020-02-19 17:27:36                                                 []   \n",
       "1    2020-02-19 17:27:36                                                 []   \n",
       "2    2020-02-19 17:27:36                                                 []   \n",
       "3    2020-02-19 17:11:40                                                 []   \n",
       "4    2020-02-19 17:11:40                                                 []   \n",
       "...                  ...                                                ...   \n",
       "5357 2020-02-12 21:08:20  [https://twitter.com/bfmparis/status/117131151...   \n",
       "5358 2020-02-12 21:08:20  [https://twitter.com/bfmparis/status/117131151...   \n",
       "5359 2020-02-12 21:08:20  [https://twitter.com/bfmparis/status/117131151...   \n",
       "5360 2020-02-12 21:08:20  [https://twitter.com/bfmparis/status/117131151...   \n",
       "5361 2020-02-12 21:08:20  [https://twitter.com/bfmparis/status/117131151...   \n",
       "\n",
       "                                                   text  retweet_count  \\\n",
       "0     @paulcng @pilorgetrezzouk @expliciteJA Tristes...              0   \n",
       "1     @paulcng @pilorgetrezzouk @expliciteJA Tristes...              0   \n",
       "2     @paulcng @pilorgetrezzouk @expliciteJA Tristes...              0   \n",
       "3     @paulcng @pilorgetrezzouk @expliciteJA ðŸ˜°ðŸ˜± c'es...              0   \n",
       "4     @paulcng @pilorgetrezzouk @expliciteJA ðŸ˜°ðŸ˜± c'es...              0   \n",
       "...                                                 ...            ...   \n",
       "5357  @MichaelWeber1 @FederationPNR @Elysee @EmmWarg...              7   \n",
       "5358  @MichaelWeber1 @FederationPNR @Elysee @EmmWarg...              7   \n",
       "5359  @MichaelWeber1 @FederationPNR @Elysee @EmmWarg...              7   \n",
       "5360  @MichaelWeber1 @FederationPNR @Elysee @EmmWarg...              7   \n",
       "5361  @MichaelWeber1 @FederationPNR @Elysee @EmmWarg...              7   \n",
       "\n",
       "      favorite_count  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "5357               9  \n",
       "5358               9  \n",
       "5359               9  \n",
       "5360               9  \n",
       "5361               9  \n",
       "\n",
       "[5362 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the graph from the edge list\n",
      "Nb of nodes: 1736\n",
      "Nb of nodes after removing nodes with degree strictly smaller than 2: 341\n",
      "removed 0 isolated nodes.\n",
      "Warning: the graph is directed.\n",
      "Period from 2020-02-12 20:24:45 to 2020-02-19 19:08:07.\n"
     ]
    }
   ],
   "source": [
    "DEGREE_MIN = 2 # Minimal number of connections in the graph\n",
    "\n",
    "G = pysad.graph_from_edgeslist(edge_df,DEGREE_MIN)\n",
    "G.name = category_name\n",
    "G.end_date = max(edge_df['date']) #max(edge_df['date'].apply(max))\n",
    "G.start_date = min(edge_df['date']) #min(edge_df['date'].apply(min))\n",
    "print('Period from {} to {}.'.format(G.start_date,G.end_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community detection to get the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communities saved on the graph as node attributes.\n",
      "Nb of partitions: 10\n"
     ]
    }
   ],
   "source": [
    "G,clusters = pysad.detect_communities(G)\n",
    "G.nb_communities = len(clusters)\n",
    "c_connectivity = pysad.cluster_connectivity(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote resultsdata2/swiss_climate_regular/20200219/globalgraph_t2_md2_graph.gexf\n"
     ]
    }
   ],
   "source": [
    "# Save the graph\n",
    "import networkx as nx\n",
    "\n",
    "graphname = 'globalgraph'\n",
    "graphfilename = results_data_path + graphname + '_t' + str(min_mentions) + '_md' + str(DEGREE_MIN) +'_graph.gexf'\n",
    "nx.write_gexf(G,graphfilename)\n",
    "print('Wrote',graphfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0.153, 0.232, 0.156, 0.174, 0.244, 0.082, 0.08, 0.266, 0.035, -0.0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_connectivity.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pysad' from '/home/benjamin/Documents/EPFL/Research/sad/sad_tweets/pysad.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(pysad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic processing of all clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracting the data from the clusters\n",
    "cluster_info_dic = {}\n",
    "for c_id in clusters:\n",
    "    cgraph = clusters[c_id]\n",
    "    cgraph = pysad.cluster_attributes(cgraph)\n",
    "    table_dic = pysad.cluster_tables(cgraph)\n",
    "    cluster_filename = results_data_path + 'cluster' + str(c_id)\n",
    "    cluster_info_dic[c_id] = {}\n",
    "    cluster_info_dic[c_id]['info_table'] = table_dic\n",
    "    cluster_info_dic[c_id]['filename'] = cluster_filename    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding global infos\n",
    "# keywords\n",
    "corpus = pysad.get_corpus(cluster_info_dic)\n",
    "keyword_dic = pysad.tfidf(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to resultsdata2/swiss_climate_regular/20200219/cluster0_infos.xlsx\n",
      "Graph saved to resultsdata2/swiss_climate_regular/20200219/cluster0graph.gexf\n",
      "Data saved to resultsdata2/swiss_climate_regular/20200219/cluster1_infos.xlsx\n",
      "Graph saved to resultsdata2/swiss_climate_regular/20200219/cluster1graph.gexf\n",
      "Data saved to resultsdata2/swiss_climate_regular/20200219/cluster2_infos.xlsx\n",
      "Graph saved to resultsdata2/swiss_climate_regular/20200219/cluster2graph.gexf\n",
      "Data saved to resultsdata2/swiss_climate_regular/20200219/cluster3_infos.xlsx\n",
      "Graph saved to resultsdata2/swiss_climate_regular/20200219/cluster3graph.gexf\n",
      "Data saved to resultsdata2/swiss_climate_regular/20200219/cluster4_infos.xlsx\n",
      "Graph saved to resultsdata2/swiss_climate_regular/20200219/cluster4graph.gexf\n",
      "Data saved to resultsdata2/swiss_climate_regular/20200219/cluster5_infos.xlsx\n",
      "Graph saved to resultsdata2/swiss_climate_regular/20200219/cluster5graph.gexf\n",
      "Data saved to resultsdata2/swiss_climate_regular/20200219/cluster6_infos.xlsx\n",
      "Graph saved to resultsdata2/swiss_climate_regular/20200219/cluster6graph.gexf\n",
      "Data saved to resultsdata2/swiss_climate_regular/20200219/cluster7_infos.xlsx\n",
      "Graph saved to resultsdata2/swiss_climate_regular/20200219/cluster7graph.gexf\n",
      "Data saved to resultsdata2/swiss_climate_regular/20200219/cluster8_infos.xlsx\n",
      "Graph saved to resultsdata2/swiss_climate_regular/20200219/cluster8graph.gexf\n",
      "Data saved to resultsdata2/swiss_climate_regular/20200219/cluster9_infos.xlsx\n",
      "Graph saved to resultsdata2/swiss_climate_regular/20200219/cluster9graph.gexf\n"
     ]
    }
   ],
   "source": [
    "# gathering global info\n",
    "# Saving in excel files\n",
    "for c_id in cluster_info_dic:\n",
    "    info_table = cluster_info_dic[c_id]['info_table']\n",
    "    info_table['keywords'] = keyword_dic[c_id]\n",
    "    cluster_general_info = {'cluster id': c_id, 'Nb users': clusters[c_id].number_of_nodes(), \n",
    "                           'Nb of tweets':clusters[c_id].size(weight='weight'),\n",
    "                           'Start date': str(G.start_date),\n",
    "                           'End date': str(G.end_date),\n",
    "                           'Search topic': category_name,\n",
    "                           'cluster connectivity': c_connectivity[c_id]}\n",
    "    cluster_general_df = pd.DataFrame.from_dict([cluster_general_info])\n",
    "    #info_table = {'cluster':cluster_general_df, **info_table}\n",
    "    sheet1 = pd.concat([cluster_general_df,info_table['hashtags'],info_table['keywords']],axis=1)\n",
    "    tweet_table = info_table['text']\n",
    "    cluster_indicators = pd.DataFrame([pysad.compute_cluster_indicators(clusters[c_id])])\n",
    "    excel_data = {'cluster':sheet1, 'tweets':tweet_table, 'indicators': cluster_indicators}\n",
    "    #excel_data = info_table\n",
    "    pysad.save_excel(excel_data,cluster_info_dic[c_id]['filename'] + '_infos.xlsx', table_format='Fanny')\n",
    "    pysad.save_graph(clusters[c_id],cluster_info_dic[c_id]['filename'] + 'graph.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
