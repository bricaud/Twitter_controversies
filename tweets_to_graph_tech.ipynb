{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting the data from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Twython class\n",
    "from twython import Twython\n",
    "import json\n",
    "\n",
    "# Load credentials from json file\n",
    "with open(\"twitter_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file)\n",
    "\n",
    "# Instantiate an object\n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Lines used to create the json file of initial users\n",
    "\n",
    "#username = 'templivs'\n",
    "#username_list  = ['GilbertCollard','dav_dec','Carbongate','bcassoret',\n",
    "#                  'Electroversenet','thinkfree55', 'KlassLib','sauvonsleclimat']\n",
    "\n",
    "climate_controversial = ['francisrichard','MazdaArtaxerxes','templivs','prontipronto',\n",
    "                'Chabadalala','cocktail2Funk','HopitalC',\n",
    "                'riva_vitale','Remifasol57','AitiDouze', 'QAnonAustria1', 'gotteswerk2411']\n",
    "\n",
    "swiss_accounts = ['KlimaschutzCH', 'GrueneCH', 'proclimCH', 'EperonP', 'MathiasTemujin',\n",
    "                  'klimastreik', 'AlimEquitables', 'ProNaturaSuisse', 'vertliberaux', 'Munsterma',\n",
    "                  'bourg_d', 'LesVertsSuisses', 'ClimatSuisse', 'gpsuisse', 'IliasPanchard', 'ATE_Suisse']\n",
    "\n",
    "immigration = ['Kalvingrad1291','democratesuisse','VigilanceIslam','lioneljonson01','ChWilhou',\n",
    "               'HunterSThomson2','A_Addams_','ObservateursCH','JuanCandida','novopress']\n",
    "\n",
    "# tech found at https://www.lesechos.fr/2016/06/twitter-15-comptes-dexperts-a-suivre-210636\n",
    "tech = ['fwred','Alban_Jarry','jdomerchet','DenisCosnard','Plaigneau','roxannevarza','LouisaMesnard',\n",
    "       'GGibault','Nicolas_Colin']\n",
    "\n",
    "accounts_dic = {}\n",
    "accounts_dic['swiss_climate_regular'] = swiss_accounts\n",
    "accounts_dic['swiss_climate_controversial'] = climate_controversial\n",
    "accounts_dic['swiss_immigration'] = immigration\n",
    "accounts_dic['french_tech_lesechos'] = tech\n",
    "with open('initial_accounts.txt', 'w') as outfile:\n",
    "    json.dump(accounts_dic, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date string = 191218\n"
     ]
    }
   ],
   "source": [
    "with open('initial_accounts.txt') as json_file:\n",
    "    initial_user_accounts = json.load(json_file)\n",
    "\n",
    "category_name = 'french_tech_lesechos'\n",
    "username_list = initial_user_accounts[category_name]\n",
    "# create the path to save the experiment indexed with a date\n",
    "today = date.today()\n",
    "date_string = today.strftime(\"%y%m%d\")\n",
    "print(\"date string =\", date_string)\n",
    "\n",
    "#date_string = '191128'\n",
    "\n",
    "data_path = category_name + date_string+ '/'\n",
    "#get_tweets = python_tweets.get_user_timeline(screen_name = username,  \n",
    "#                                           count = 200, include_rts = True)\n",
    "if not os.path.isdir(data_path):\n",
    "    os.mkdir(data_path)\n",
    "    print('Path created:',data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pysad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold set to 2 mentions.\n",
      "Number of days covered: 7\n"
     ]
    }
   ],
   "source": [
    "thres = 2 # minimal number of mentions to keep\n",
    "max_day_old = 7 # number max of days in the past\n",
    "print('Threshold set to {} mentions.'.format(thres))\n",
    "print('Number of days covered:',max_day_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting the tweets for the last 7 days.\n",
      "\n",
      "******* Processing users at 0-hop distance *******\n",
      "Collecting the tweets for the last 7 days.\n",
      "Processing fwred\n",
      "Writing 35 tweets in tech_reduced191218/fwred_mentions_t2.csv.\n",
      "Processing Alban_Jarry\n",
      "Writing 43 tweets in tech_reduced191218/Alban_Jarry_mentions_t2.csv.\n",
      "Processing jdomerchet\n",
      "Writing 68 tweets in tech_reduced191218/jdomerchet_mentions_t2.csv.\n",
      "Processing DenisCosnard\n",
      "Writing 10 tweets in tech_reduced191218/DenisCosnard_mentions_t2.csv.\n",
      "Processing Plaigneau\n",
      "Writing 1 tweets in tech_reduced191218/Plaigneau_mentions_t2.csv.\n",
      "Processing roxannevarza\n",
      "Writing 27 tweets in tech_reduced191218/roxannevarza_mentions_t2.csv.\n",
      "Processing LouisaMesnard\n",
      "Empty tweet list. Processing stopped for user  LouisaMesnard\n",
      "Processing GGibault\n",
      "Empty tweet list. Processing stopped for user  GGibault\n",
      "Processing Nicolas_Colin\n",
      "Writing 95 tweets in tech_reduced191218/Nicolas_Colin_mentions_t2.csv.\n",
      "\n",
      "******* Processing users at 1-hop distance *******\n",
      "Collecting the tweets for the last 7 days.\n",
      "Processing Vitolae\n",
      "Writing 65 tweets in tech_reduced191218/Vitolae_mentions_t2.csv.\n",
      "Processing mgurri\n",
      "Writing 28 tweets in tech_reduced191218/mgurri_mentions_t2.csv.\n",
      "Processing ecb\n",
      "Writing 10 tweets in tech_reduced191218/ecb_mentions_t2.csv.\n",
      "Processing Siftedeu\n",
      "Writing 118 tweets in tech_reduced191218/Siftedeu_mentions_t2.csv.\n",
      "Processing ArianeChemin\n",
      "Writing 9 tweets in tech_reduced191218/ArianeChemin_mentions_t2.csv.\n",
      "Processing michaelsteen\n",
      "Writing 47 tweets in tech_reduced191218/michaelsteen_mentions_t2.csv.\n",
      "Processing briannekimmel\n",
      "Writing 102 tweets in tech_reduced191218/briannekimmel_mentions_t2.csv.\n",
      "Processing RossySheil\n",
      "Writing 8 tweets in tech_reduced191218/RossySheil_mentions_t2.csv.\n",
      "Processing Lagarde\n",
      "Writing 6 tweets in tech_reduced191218/Lagarde_mentions_t2.csv.\n",
      "Processing irefeurope\n",
      "Writing 18 tweets in tech_reduced191218/irefeurope_mentions_t2.csv.\n",
      "Processing quatremer\n",
      "Writing 89 tweets in tech_reduced191218/quatremer_mentions_t2.csv.\n",
      "Processing joinstationf\n",
      "Writing 15 tweets in tech_reduced191218/joinstationf_mentions_t2.csv.\n",
      "Processing ClaireBerlinski\n",
      "Writing 41 tweets in tech_reduced191218/ClaireBerlinski_mentions_t2.csv.\n",
      "Processing abouilhet\n",
      "Writing 6 tweets in tech_reduced191218/abouilhet_mentions_t2.csv.\n",
      "Processing PeterZeihan\n",
      "Writing 52 tweets in tech_reduced191218/PeterZeihan_mentions_t2.csv.\n",
      "Processing wttj_fr\n",
      "Writing 3 tweets in tech_reduced191218/wttj_fr_mentions_t2.csv.\n",
      "Processing thestartup_\n",
      "Writing 2 tweets in tech_reduced191218/thestartup__mentions_t2.csv.\n",
      "Processing pietphc\n",
      "Writing 9 tweets in tech_reduced191218/pietphc_mentions_t2.csv.\n",
      "Processing BlancheNoire1\n",
      "Writing 113 tweets in tech_reduced191218/BlancheNoire1_mentions_t2.csv.\n",
      "Processing Altimor\n",
      "Writing 18 tweets in tech_reduced191218/Altimor_mentions_t2.csv.\n",
      "Processing JLTHIERIOT\n",
      "Writing 21 tweets in tech_reduced191218/JLTHIERIOT_mentions_t2.csv.\n",
      "Processing Skolimowski\n",
      "Writing 20 tweets in tech_reduced191218/Skolimowski_mentions_t2.csv.\n",
      "Processing threader_app\n",
      "Writing 112 tweets in tech_reduced191218/threader_app_mentions_t2.csv.\n",
      "Processing vgr\n",
      "Writing 35 tweets in tech_reduced191218/vgr_mentions_t2.csv.\n",
      "Processing jeuasommenulle\n",
      "Writing 50 tweets in tech_reduced191218/jeuasommenulle_mentions_t2.csv.\n",
      "Processing N_Lecaussin\n",
      "Writing 52 tweets in tech_reduced191218/N_Lecaussin_mentions_t2.csv.\n",
      "Processing indica\n",
      "Writing 46 tweets in tech_reduced191218/indica_mentions_t2.csv.\n",
      "Processing YGuichaoua\n",
      "Writing 17 tweets in tech_reduced191218/YGuichaoua_mentions_t2.csv.\n",
      "Processing DanielKorski\n",
      "Writing 80 tweets in tech_reduced191218/DanielKorski_mentions_t2.csv.\n",
      "Processing lopinion_fr\n",
      "Writing 19 tweets in tech_reduced191218/lopinion_fr_mentions_t2.csv.\n",
      "Processing atomico\n",
      "Writing 37 tweets in tech_reduced191218/atomico_mentions_t2.csv.\n",
      "\n",
      "******* Processing users at 2-hop distance *******\n",
      "Collecting the tweets for the last 7 days.\n",
      "Processing stubborncurias\n",
      "Writing 22 tweets in tech_reduced191218/stubborncurias_mentions_t2.csv.\n",
      "Processing CapHoratius\n",
      "Writing 10 tweets in tech_reduced191218/CapHoratius_mentions_t2.csv.\n",
      "Processing Bright_dejoseph\n",
      "Writing 76 tweets in tech_reduced191218/Bright_dejoseph_mentions_t2.csv.\n",
      "Processing dr_ionita\n",
      "Empty tweet list. Processing stopped for user  dr_ionita\n",
      "Processing gregclaeys\n",
      "Writing 15 tweets in tech_reduced191218/gregclaeys_mentions_t2.csv.\n",
      "Processing shl\n",
      "Writing 45 tweets in tech_reduced191218/shl_mentions_t2.csv.\n",
      "Processing PaulJDavies\n",
      "Writing 30 tweets in tech_reduced191218/PaulJDavies_mentions_t2.csv.\n",
      "Processing achilleas999\n",
      "Writing 5 tweets in tech_reduced191218/achilleas999_mentions_t2.csv.\n",
      "Processing neozinho\n",
      "Writing 48 tweets in tech_reduced191218/neozinho_mentions_t2.csv.\n",
      "Processing akoz33\n",
      "Writing 54 tweets in tech_reduced191218/akoz33_mentions_t2.csv.\n",
      "Processing mattwarman\n",
      "Writing 25 tweets in tech_reduced191218/mattwarman_mentions_t2.csv.\n",
      "Processing thomasforth\n",
      "Writing 72 tweets in tech_reduced191218/thomasforth_mentions_t2.csv.\n",
      "Processing marcelsel\n",
      "Writing 73 tweets in tech_reduced191218/marcelsel_mentions_t2.csv.\n",
      "Processing DrHannahWhite\n",
      "Writing 29 tweets in tech_reduced191218/DrHannahWhite_mentions_t2.csv.\n",
      "Processing foreignoffice\n",
      "Writing 16 tweets in tech_reduced191218/foreignoffice_mentions_t2.csv.\n",
      "Processing CommanderHam\n",
      "Writing 19 tweets in tech_reduced191218/CommanderHam_mentions_t2.csv.\n",
      "Processing The_Lagrangian\n",
      "Writing 62 tweets in tech_reduced191218/The_Lagrangian_mentions_t2.csv.\n",
      "Processing Ben_Reinhardt\n",
      "Writing 17 tweets in tech_reduced191218/Ben_Reinhardt_mentions_t2.csv.\n",
      "Processing sophiabendz\n",
      "Writing 69 tweets in tech_reduced191218/sophiabendz_mentions_t2.csv.\n",
      "Processing mvanhulten\n",
      "Writing 66 tweets in tech_reduced191218/mvanhulten_mentions_t2.csv.\n",
      "Processing JLBourlanges\n",
      "Writing 15 tweets in tech_reduced191218/JLBourlanges_mentions_t2.csv.\n",
      "Processing pesasafi\n",
      "Writing 71 tweets in tech_reduced191218/pesasafi_mentions_t2.csv.\n",
      "Processing Conaw\n",
      "Writing 68 tweets in tech_reduced191218/Conaw_mentions_t2.csv.\n",
      "Processing ravernkoh\n",
      "Writing 52 tweets in tech_reduced191218/ravernkoh_mentions_t2.csv.\n",
      "Processing founderwalkerf1\n",
      "Writing 15 tweets in tech_reduced191218/founderwalkerf1_mentions_t2.csv.\n",
      "Processing tradegovuk\n",
      "Writing 3 tweets in tech_reduced191218/tradegovuk_mentions_t2.csv.\n",
      "Processing agnesbuzyn\n",
      "Writing 13 tweets in tech_reduced191218/agnesbuzyn_mentions_t2.csv.\n",
      "Processing cy_lacarriere\n",
      "Writing 30 tweets in tech_reduced191218/cy_lacarriere_mentions_t2.csv.\n",
      "Processing BBC_Culture\n",
      "Writing 14 tweets in tech_reduced191218/BBC_Culture_mentions_t2.csv.\n",
      "Processing StarlingBank\n",
      "Writing 85 tweets in tech_reduced191218/StarlingBank_mentions_t2.csv.\n",
      "Processing GCharing\n",
      "Writing 79 tweets in tech_reduced191218/GCharing_mentions_t2.csv.\n",
      "Processing LIGNEP_SNCF\n",
      "Writing 59 tweets in tech_reduced191218/LIGNEP_SNCF_mentions_t2.csv.\n",
      "Processing eriktorenberg\n",
      "Writing 34 tweets in tech_reduced191218/eriktorenberg_mentions_t2.csv.\n",
      "Processing aled_mj\n",
      "Writing 35 tweets in tech_reduced191218/aled_mj_mentions_t2.csv.\n",
      "Processing CyborgOntologie\n",
      "Writing 64 tweets in tech_reduced191218/CyborgOntologie_mentions_t2.csv.\n",
      "Processing pcanfin\n",
      "Writing 15 tweets in tech_reduced191218/pcanfin_mentions_t2.csv.\n",
      "Processing DCMS\n",
      "Writing 5 tweets in tech_reduced191218/DCMS_mentions_t2.csv.\n",
      "Processing nbouzou\n",
      "Writing 17 tweets in tech_reduced191218/nbouzou_mentions_t2.csv.\n",
      "Processing RevolutApp\n",
      "Writing 70 tweets in tech_reduced191218/RevolutApp_mentions_t2.csv.\n",
      "Processing vonderleyen\n",
      "Writing 4 tweets in tech_reduced191218/vonderleyen_mentions_t2.csv.\n",
      "Processing Conservatives\n",
      "Writing 35 tweets in tech_reduced191218/Conservatives_mentions_t2.csv.\n",
      "Processing RichardALJones\n",
      "Writing 15 tweets in tech_reduced191218/RichardALJones_mentions_t2.csv.\n",
      "Processing LeeARisk\n",
      "Writing 34 tweets in tech_reduced191218/LeeARisk_mentions_t2.csv.\n",
      "Processing hhesterm\n",
      "Writing 56 tweets in tech_reduced191218/hhesterm_mentions_t2.csv.\n",
      "Processing ITrippenbach\n",
      "Writing 47 tweets in tech_reduced191218/ITrippenbach_mentions_t2.csv.\n",
      "Processing FT\n",
      "Empty tweet list. Processing stopped for user  FT\n",
      "Processing Rahul_J_Mathur\n",
      "Writing 111 tweets in tech_reduced191218/Rahul_J_Mathur_mentions_t2.csv.\n",
      "Processing PromonetA\n",
      "Writing 72 tweets in tech_reduced191218/PromonetA_mentions_t2.csv.\n",
      "Processing stewart\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 23 tweets in tech_reduced191218/stewart_mentions_t2.csv.\n",
      "Processing LaREM_AN\n",
      "Writing 89 tweets in tech_reduced191218/LaREM_AN_mentions_t2.csv.\n",
      "Processing vellaviens\n",
      "Writing 119 tweets in tech_reduced191218/vellaviens_mentions_t2.csv.\n",
      "Processing ArthurViret\n",
      "Writing 57 tweets in tech_reduced191218/ArthurViret_mentions_t2.csv.\n",
      "Processing delevoye\n",
      "Empty tweet list. Processing stopped for user  delevoye\n",
      "Processing sarahdrinkwater\n",
      "Writing 49 tweets in tech_reduced191218/sarahdrinkwater_mentions_t2.csv.\n",
      "Processing robert19pearson\n",
      "Writing 62 tweets in tech_reduced191218/robert19pearson_mentions_t2.csv.\n",
      "Processing pixlpa\n",
      "Writing 30 tweets in tech_reduced191218/pixlpa_mentions_t2.csv.\n",
      "Processing MarteauOlivier\n",
      "Writing 22 tweets in tech_reduced191218/MarteauOlivier_mentions_t2.csv.\n",
      "Processing PCF\n",
      "Writing 55 tweets in tech_reduced191218/PCF_mentions_t2.csv.\n",
      "Processing deanschneiderFp\n",
      "Writing 2 tweets in tech_reduced191218/deanschneiderFp_mentions_t2.csv.\n",
      "Processing tasshinfogleman\n",
      "Writing 14 tweets in tech_reduced191218/tasshinfogleman_mentions_t2.csv.\n",
      "Processing Andreas_Schwab\n",
      "Writing 72 tweets in tech_reduced191218/Andreas_Schwab_mentions_t2.csv.\n",
      "Processing Callystor\n",
      "Writing 60 tweets in tech_reduced191218/Callystor_mentions_t2.csv.\n",
      "Processing pietraszewski_l\n",
      "Writing 23 tweets in tech_reduced191218/pietraszewski_l_mentions_t2.csv.\n",
      "Processing robert_zubrin\n",
      "Writing 32 tweets in tech_reduced191218/robert_zubrin_mentions_t2.csv.\n",
      "Processing MaxBoot\n",
      "Writing 73 tweets in tech_reduced191218/MaxBoot_mentions_t2.csv.\n",
      "Processing ddamarzit\n",
      "Writing 10 tweets in tech_reduced191218/ddamarzit_mentions_t2.csv.\n",
      "Processing chasrmartin\n",
      "Writing 112 tweets in tech_reduced191218/chasrmartin_mentions_t2.csv.\n",
      "Processing 828AS1\n",
      "Writing 16 tweets in tech_reduced191218/828AS1_mentions_t2.csv.\n",
      "Processing doriantaylor\n",
      "Writing 50 tweets in tech_reduced191218/doriantaylor_mentions_t2.csv.\n",
      "Processing remigodeau\n",
      "Writing 51 tweets in tech_reduced191218/remigodeau_mentions_t2.csv.\n",
      "Processing Joshbradford\n",
      "Writing 28 tweets in tech_reduced191218/Joshbradford_mentions_t2.csv.\n",
      "Processing andrewjb_\n",
      "Writing 38 tweets in tech_reduced191218/andrewjb__mentions_t2.csv.\n",
      "Processing CaroVigoureux\n",
      "Writing 18 tweets in tech_reduced191218/CaroVigoureux_mentions_t2.csv.\n",
      "Processing OdysseanProject\n",
      "Writing 2 tweets in tech_reduced191218/OdysseanProject_mentions_t2.csv.\n",
      "Processing PostOpinions\n",
      "Writing 48 tweets in tech_reduced191218/PostOpinions_mentions_t2.csv.\n",
      "Processing shjfrench\n",
      "Writing 54 tweets in tech_reduced191218/shjfrench_mentions_t2.csv.\n",
      "Processing i_woodford\n",
      "Writing 27 tweets in tech_reduced191218/i_woodford_mentions_t2.csv.\n",
      "Processing azeem\n",
      "Writing 84 tweets in tech_reduced191218/azeem_mentions_t2.csv.\n",
      "Processing SaadainH\n",
      "Writing 42 tweets in tech_reduced191218/SaadainH_mentions_t2.csv.\n",
      "Processing leftliberslayer\n",
      "Writing 92 tweets in tech_reduced191218/leftliberslayer_mentions_t2.csv.\n",
      "Processing libe\n",
      "Writing 18 tweets in tech_reduced191218/libe_mentions_t2.csv.\n",
      "Processing CollectInterHop\n",
      "Writing 73 tweets in tech_reduced191218/CollectInterHop_mentions_t2.csv.\n",
      "Processing AssezAimable\n",
      "Writing 58 tweets in tech_reduced191218/AssezAimable_mentions_t2.csv.\n",
      "Processing EEHines\n",
      "Writing 55 tweets in tech_reduced191218/EEHines_mentions_t2.csv.\n",
      "Processing beisgovuk\n",
      "Writing 9 tweets in tech_reduced191218/beisgovuk_mentions_t2.csv.\n",
      "Processing EPhilippePM\n",
      "Writing 5 tweets in tech_reduced191218/EPhilippePM_mentions_t2.csv.\n",
      "Processing gavinsblog\n",
      "Writing 65 tweets in tech_reduced191218/gavinsblog_mentions_t2.csv.\n",
      "Processing stianwestlake\n",
      "Writing 97 tweets in tech_reduced191218/stianwestlake_mentions_t2.csv.\n",
      "Processing cgiorgi\n",
      "Writing 8 tweets in tech_reduced191218/cgiorgi_mentions_t2.csv.\n",
      "Processing LaurentPahpy\n",
      "Writing 40 tweets in tech_reduced191218/LaurentPahpy_mentions_t2.csv.\n",
      "Processing diviacaroline\n",
      "Writing 25 tweets in tech_reduced191218/diviacaroline_mentions_t2.csv.\n",
      "Processing GDSTeam\n",
      "Writing 9 tweets in tech_reduced191218/GDSTeam_mentions_t2.csv.\n",
      "Processing sergio_mz\n",
      "Writing 7 tweets in tech_reduced191218/sergio_mz_mentions_t2.csv.\n",
      "Processing PDV_Figaro\n",
      "Writing 25 tweets in tech_reduced191218/PDV_Figaro_mentions_t2.csv.\n",
      "Processing arusbridger\n",
      "Writing 75 tweets in tech_reduced191218/arusbridger_mentions_t2.csv.\n",
      "Processing SapienzaRoma\n",
      "Writing 20 tweets in tech_reduced191218/SapienzaRoma_mentions_t2.csv.\n",
      "Processing Narasuara1\n",
      "Empty tweet list. Processing stopped for user  Narasuara1\n",
      "Processing SamoBurja\n",
      "Writing 24 tweets in tech_reduced191218/SamoBurja_mentions_t2.csv.\n",
      "Processing DrBrexit\n",
      "Writing 40 tweets in tech_reduced191218/DrBrexit_mentions_t2.csv.\n",
      "Processing EamonnYoung1\n",
      "Writing 36 tweets in tech_reduced191218/EamonnYoung1_mentions_t2.csv.\n",
      "Processing wttj\n",
      "Empty tweet list. Processing stopped for user  wttj\n",
      "Processing noUpside\n",
      "Writing 55 tweets in tech_reduced191218/noUpside_mentions_t2.csv.\n",
      "Processing Republicains_An\n",
      "Writing 28 tweets in tech_reduced191218/Republicains_An_mentions_t2.csv.\n",
      "Processing Banqkys\n",
      "Writing 11 tweets in tech_reduced191218/Banqkys_mentions_t2.csv.\n",
      "Processing bldgblog\n",
      "Empty tweet list. Processing stopped for user  bldgblog\n",
      "Processing Sebastish\n",
      "Writing 50 tweets in tech_reduced191218/Sebastish_mentions_t2.csv.\n",
      "Processing JP_O\n",
      "Writing 76 tweets in tech_reduced191218/JP_O_mentions_t2.csv.\n",
      "Processing lisampmunoz\n",
      "Writing 7 tweets in tech_reduced191218/lisampmunoz_mentions_t2.csv.\n",
      "Processing VinMurria\n",
      "Empty tweet list. Processing stopped for user  VinMurria\n",
      "Processing jeremiedd\n",
      "Writing 12 tweets in tech_reduced191218/jeremiedd_mentions_t2.csv.\n",
      "Processing NathanLatka\n",
      "Writing 25 tweets in tech_reduced191218/NathanLatka_mentions_t2.csv.\n",
      "Processing Le_Figaro\n",
      "Writing 38 tweets in tech_reduced191218/Le_Figaro_mentions_t2.csv.\n",
      "Processing SicTransit74\n",
      "Writing 65 tweets in tech_reduced191218/SicTransit74_mentions_t2.csv.\n",
      "Processing josephcaiphas\n",
      "Writing 16 tweets in tech_reduced191218/josephcaiphas_mentions_t2.csv.\n",
      "Processing tombarfield\n",
      "Writing 38 tweets in tech_reduced191218/tombarfield_mentions_t2.csv.\n",
      "Processing atduskgreg\n",
      "Writing 12 tweets in tech_reduced191218/atduskgreg_mentions_t2.csv.\n",
      "Processing FerghaneA\n",
      "Writing 31 tweets in tech_reduced191218/FerghaneA_mentions_t2.csv.\n",
      "Processing maijapalmer\n",
      "Writing 43 tweets in tech_reduced191218/maijapalmer_mentions_t2.csv.\n",
      "Processing threadascii\n",
      "Writing 31 tweets in tech_reduced191218/threadascii_mentions_t2.csv.\n",
      "Processing NSegaunes\n",
      "Writing 17 tweets in tech_reduced191218/NSegaunes_mentions_t2.csv.\n",
      "Processing Olivier_Auguste\n",
      "Writing 62 tweets in tech_reduced191218/Olivier_Auguste_mentions_t2.csv.\n",
      "Processing KTRivoire\n",
      "Writing 10 tweets in tech_reduced191218/KTRivoire_mentions_t2.csv.\n",
      "Processing microsofttech\n",
      "Empty tweet list. Processing stopped for user  microsofttech\n",
      "Processing Tinder\n",
      "Writing 1 tweets in tech_reduced191218/Tinder_mentions_t2.csv.\n",
      "Processing nicolasbeytout\n",
      "Empty tweet list. Processing stopped for user  nicolasbeytout\n",
      "Processing pressmium\n",
      "Writing 12 tweets in tech_reduced191218/pressmium_mentions_t2.csv.\n",
      "Processing JRegoyos\n",
      "Writing 4 tweets in tech_reduced191218/JRegoyos_mentions_t2.csv.\n",
      "Processing emmaljones\n",
      "Writing 20 tweets in tech_reduced191218/emmaljones_mentions_t2.csv.\n",
      "Processing mikebutcher\n",
      "Writing 91 tweets in tech_reduced191218/mikebutcher_mentions_t2.csv.\n",
      "Processing susannahjclark\n",
      "Twitter API returned error 401 for user susannahjclark.\n",
      "Empty tweet list. Processing stopped for user  susannahjclark\n",
      "Processing MStothard\n",
      "Writing 170 tweets in tech_reduced191218/MStothard_mentions_t2.csv.\n",
      "Processing visakanv\n",
      "Writing 69 tweets in tech_reduced191218/visakanv_mentions_t2.csv.\n",
      "Processing jwaintraub\n",
      "Writing 66 tweets in tech_reduced191218/jwaintraub_mentions_t2.csv.\n",
      "Processing BorisJohnson\n",
      "Writing 2 tweets in tech_reduced191218/BorisJohnson_mentions_t2.csv.\n",
      "Processing amyrlewin\n",
      "Writing 47 tweets in tech_reduced191218/amyrlewin_mentions_t2.csv.\n"
     ]
    }
   ],
   "source": [
    "users_dic = {'username':[], 'Nb_mentions': [], 'mentions_of_mentions': []}\n",
    "print('Collecting the tweets for the last {} days.'.format(max_day_old))\n",
    "exploration_depth = 3\n",
    "total_username_list = username_list\n",
    "for depth in range(exploration_depth):\n",
    "    print('')\n",
    "    print('******* Processing users at {}-hop distance *******'.format(depth))\n",
    "    new_users_list,users_df = pysad.process_user_list(python_tweets, data_path, username_list, thres=thres, max_day_old=max_day_old)\n",
    "    #New users to collect:\n",
    "    username_list = list(set(new_users_list).difference(set(total_username_list))) # remove the one already collected\n",
    "    total_username_list += username_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of users collected:\n",
      "767 767\n"
     ]
    }
   ],
   "source": [
    "print('Total number of users collected:')\n",
    "print(len(total_username_list),len(set(total_username_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the saved data into an edge table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tech_reduced191218/roxannevarza_mentions_t2.csv with 27 tweets.\n",
      "tech_reduced191218/pietraszewski_l_mentions_t2.csv with 23 tweets.\n",
      "tech_reduced191218/DanielKorski_mentions_t2.csv with 80 tweets.\n",
      "tech_reduced191218/beisgovuk_mentions_t2.csv with 9 tweets.\n",
      "tech_reduced191218/The_Lagrangian_mentions_t2.csv with 62 tweets.\n",
      "tech_reduced191218/jwaintraub_mentions_t2.csv with 66 tweets.\n",
      "tech_reduced191218/JLBourlanges_mentions_t2.csv with 15 tweets.\n",
      "tech_reduced191218/Vitolae_mentions_t2.csv with 65 tweets.\n",
      "tech_reduced191218/tasshinfogleman_mentions_t2.csv with 14 tweets.\n",
      "tech_reduced191218/bheater_mentions_t2.csv with 26 tweets.\n",
      "tech_reduced191218/_awbery__mentions_t2.csv with 35 tweets.\n",
      "tech_reduced191218/irefeurope_mentions_t2.csv with 18 tweets.\n",
      "tech_reduced191218/stewart_mentions_t2.csv with 23 tweets.\n",
      "tech_reduced191218/foreignoffice_mentions_t2.csv with 16 tweets.\n",
      "tech_reduced191218/SicTransit74_mentions_t2.csv with 65 tweets.\n",
      "tech_reduced191218/StarlingBank_mentions_t2.csv with 85 tweets.\n",
      "tech_reduced191218/colbymommy_mentions_t2.csv with 64 tweets.\n",
      "tech_reduced191218/Nicolas_Colin_mentions_t2.csv with 95 tweets.\n",
      "tech_reduced191218/Tinder_mentions_t2.csv with 1 tweets.\n",
      "tech_reduced191218/atomico_mentions_t2.csv with 37 tweets.\n",
      "tech_reduced191218/emmaljones_mentions_t2.csv with 20 tweets.\n",
      "tech_reduced191218/Yascha_Mounk_mentions_t2.csv with 15 tweets.\n",
      "tech_reduced191218/delevoye_mentions_t2.csv with 1 tweets.\n",
      "tech_reduced191218/Bright_dejoseph_mentions_t2.csv with 76 tweets.\n",
      "tech_reduced191218/SaadainH_mentions_t2.csv with 42 tweets.\n",
      "tech_reduced191218/threader_app_mentions_t2.csv with 112 tweets.\n",
      "tech_reduced191218/carolynnlook_mentions_t2.csv with 15 tweets.\n",
      "tech_reduced191218/ITrippenbach_mentions_t2.csv with 47 tweets.\n",
      "tech_reduced191218/neozinho_mentions_t2.csv with 48 tweets.\n",
      "tech_reduced191218/arusbridger_mentions_t2.csv with 75 tweets.\n",
      "tech_reduced191218/thomasforth_mentions_t2.csv with 72 tweets.\n",
      "tech_reduced191218/RevolutApp_mentions_t2.csv with 70 tweets.\n",
      "tech_reduced191218/mgurri_mentions_t2.csv with 28 tweets.\n",
      "tech_reduced191218/fredericl_mentions_t2.csv with 6 tweets.\n",
      "tech_reduced191218/taavet_mentions_t2.csv with 4 tweets.\n",
      "tech_reduced191218/ecb_mentions_t2.csv with 10 tweets.\n",
      "tech_reduced191218/BBC_Culture_mentions_t2.csv with 14 tweets.\n",
      "tech_reduced191218/PaulJDavies_mentions_t2.csv with 30 tweets.\n",
      "tech_reduced191218/CristyP2000_mentions_t2.csv with 47 tweets.\n",
      "tech_reduced191218/Louih73_mentions_t2.csv with 15 tweets.\n",
      "tech_reduced191218/mvanhulten_mentions_t2.csv with 66 tweets.\n",
      "tech_reduced191218/remigodeau_mentions_t2.csv with 51 tweets.\n",
      "tech_reduced191218/quatremer_mentions_t2.csv with 89 tweets.\n",
      "tech_reduced191218/Skolimowski_mentions_t2.csv with 20 tweets.\n",
      "tech_reduced191218/JP_O_mentions_t2.csv with 76 tweets.\n",
      "tech_reduced191218/etherington_mentions_t2.csv with 8 tweets.\n",
      "tech_reduced191218/visakanv_mentions_t2.csv with 69 tweets.\n",
      "tech_reduced191218/amyrlewin_mentions_t2.csv with 47 tweets.\n",
      "tech_reduced191218/PeterZeihan_mentions_t2.csv with 52 tweets.\n",
      "tech_reduced191218/CollectInterHop_mentions_t2.csv with 73 tweets.\n",
      "tech_reduced191218/mikebutcher_mentions_t2.csv with 91 tweets.\n",
      "tech_reduced191218/Banqkys_mentions_t2.csv with 11 tweets.\n",
      "tech_reduced191218/LorcanRK_mentions_t2.csv with 35 tweets.\n",
      "tech_reduced191218/LaREM_AN_mentions_t2.csv with 89 tweets.\n",
      "tech_reduced191218/RichardALJones_mentions_t2.csv with 15 tweets.\n",
      "tech_reduced191218/jeuasommenulle_mentions_t2.csv with 50 tweets.\n",
      "tech_reduced191218/EEHines_mentions_t2.csv with 55 tweets.\n",
      "tech_reduced191218/achilleas999_mentions_t2.csv with 5 tweets.\n",
      "tech_reduced191218/doriantaylor_mentions_t2.csv with 50 tweets.\n",
      "tech_reduced191218/tradegovuk_mentions_t2.csv with 3 tweets.\n",
      "tech_reduced191218/ddamarzit_mentions_t2.csv with 10 tweets.\n",
      "tech_reduced191218/ravernkoh_mentions_t2.csv with 52 tweets.\n",
      "tech_reduced191218/sergio_mz_mentions_t2.csv with 7 tweets.\n",
      "tech_reduced191218/warriors_mom_mentions_t2.csv with 46 tweets.\n",
      "tech_reduced191218/LeeARisk_mentions_t2.csv with 34 tweets.\n",
      "tech_reduced191218/atduskgreg_mentions_t2.csv with 12 tweets.\n",
      "tech_reduced191218/LIGNER_SNCF_mentions_t2.csv with 47 tweets.\n",
      "tech_reduced191218/EamonnYoung1_mentions_t2.csv with 36 tweets.\n",
      "tech_reduced191218/leftliberslayer_mentions_t2.csv with 92 tweets.\n",
      "tech_reduced191218/unrolporlavida_mentions_t2.csv with 208 tweets.\n",
      "tech_reduced191218/stianwestlake_mentions_t2.csv with 97 tweets.\n",
      "tech_reduced191218/sarahdrinkwater_mentions_t2.csv with 49 tweets.\n",
      "tech_reduced191218/gregclaeys_mentions_t2.csv with 15 tweets.\n",
      "tech_reduced191218/Andreas_Schwab_mentions_t2.csv with 72 tweets.\n",
      "tech_reduced191218/lisampmunoz_mentions_t2.csv with 7 tweets.\n",
      "tech_reduced191218/diviacaroline_mentions_t2.csv with 25 tweets.\n",
      "tech_reduced191218/andrewjb__mentions_t2.csv with 38 tweets.\n",
      "tech_reduced191218/josephcaiphas_mentions_t2.csv with 16 tweets.\n",
      "tech_reduced191218/Conaw_mentions_t2.csv with 68 tweets.\n",
      "tech_reduced191218/DrHannahWhite_mentions_t2.csv with 29 tweets.\n",
      "tech_reduced191218/JRegoyos_mentions_t2.csv with 4 tweets.\n",
      "tech_reduced191218/Altimor_mentions_t2.csv with 18 tweets.\n",
      "tech_reduced191218/lopinion_fr_mentions_t2.csv with 19 tweets.\n",
      "tech_reduced191218/TechCrunch_mentions_t2.csv with 31 tweets.\n",
      "tech_reduced191218/sarahintampa_mentions_t2.csv with 3 tweets.\n",
      "tech_reduced191218/EPhilippePM_mentions_t2.csv with 5 tweets.\n",
      "tech_reduced191218/jeremiedd_mentions_t2.csv with 12 tweets.\n",
      "tech_reduced191218/deanschneiderFp_mentions_t2.csv with 2 tweets.\n",
      "tech_reduced191218/Lagarde_mentions_t2.csv with 6 tweets.\n",
      "tech_reduced191218/FormerUSN_mentions_t2.csv with 101 tweets.\n",
      "tech_reduced191218/NSegaunes_mentions_t2.csv with 17 tweets.\n",
      "tech_reduced191218/OdysseanProject_mentions_t2.csv with 2 tweets.\n",
      "tech_reduced191218/ArthurViret_mentions_t2.csv with 57 tweets.\n",
      "tech_reduced191218/DrBrexit_mentions_t2.csv with 40 tweets.\n",
      "tech_reduced191218/anthonyha_mentions_t2.csv with 6 tweets.\n",
      "tech_reduced191218/eriktorenberg_mentions_t2.csv with 34 tweets.\n",
      "tech_reduced191218/fwred_mentions_t2.csv with 35 tweets.\n",
      "tech_reduced191218/stubborncurias_mentions_t2.csv with 22 tweets.\n",
      "tech_reduced191218/alex_mentions_t2.csv with 80 tweets.\n",
      "tech_reduced191218/ClaireBerlinski_mentions_t2.csv with 41 tweets.\n",
      "tech_reduced191218/Callystor_mentions_t2.csv with 60 tweets.\n",
      "tech_reduced191218/joinstationf_mentions_t2.csv with 15 tweets.\n",
      "tech_reduced191218/shjfrench_mentions_t2.csv with 54 tweets.\n",
      "tech_reduced191218/MaxDanRicard_mentions_t2.csv with 4 tweets.\n",
      "tech_reduced191218/akoz33_mentions_t2.csv with 54 tweets.\n",
      "tech_reduced191218/Plaigneau_mentions_t2.csv with 1 tweets.\n",
      "tech_reduced191218/SapienzaRoma_mentions_t2.csv with 20 tweets.\n",
      "tech_reduced191218/MStothard_mentions_t2.csv with 170 tweets.\n",
      "tech_reduced191218/nicolasbeytout_mentions_t2.csv with 3 tweets.\n",
      "tech_reduced191218/agnesbuzyn_mentions_t2.csv with 13 tweets.\n",
      "tech_reduced191218/KTRivoire_mentions_t2.csv with 10 tweets.\n",
      "tech_reduced191218/briannekimmel_mentions_t2.csv with 102 tweets.\n",
      "tech_reduced191218/Sebastish_mentions_t2.csv with 50 tweets.\n",
      "tech_reduced191218/PCF_mentions_t2.csv with 55 tweets.\n",
      "tech_reduced191218/JLTHIERIOT_mentions_t2.csv with 21 tweets.\n",
      "tech_reduced191218/ingridlunden_mentions_t2.csv with 8 tweets.\n",
      "tech_reduced191218/nbouzou_mentions_t2.csv with 17 tweets.\n",
      "tech_reduced191218/GGibault_mentions_t2.csv with 1 tweets.\n",
      "tech_reduced191218/Joshbradford_mentions_t2.csv with 28 tweets.\n",
      "tech_reduced191218/MaxBoot_mentions_t2.csv with 73 tweets.\n",
      "tech_reduced191218/DGidony_mentions_t2.csv with 2 tweets.\n",
      "tech_reduced191218/PDV_Figaro_mentions_t2.csv with 25 tweets.\n",
      "tech_reduced191218/MarteauOlivier_mentions_t2.csv with 22 tweets.\n",
      "tech_reduced191218/i_woodford_mentions_t2.csv with 27 tweets.\n",
      "tech_reduced191218/CapHoratius_mentions_t2.csv with 10 tweets.\n",
      "tech_reduced191218/vonderleyen_mentions_t2.csv with 4 tweets.\n",
      "tech_reduced191218/hhesterm_mentions_t2.csv with 56 tweets.\n",
      "tech_reduced191218/marcelsel_mentions_t2.csv with 73 tweets.\n",
      "tech_reduced191218/CyborgOntologie_mentions_t2.csv with 64 tweets.\n",
      "tech_reduced191218/shl_mentions_t2.csv with 45 tweets.\n",
      "tech_reduced191218/AssezAimable_mentions_t2.csv with 58 tweets.\n",
      "tech_reduced191218/refsrc_mentions_t2.csv with 6 tweets.\n",
      "tech_reduced191218/LaurentPahpy_mentions_t2.csv with 40 tweets.\n",
      "tech_reduced191218/azeem_mentions_t2.csv with 84 tweets.\n",
      "tech_reduced191218/GCharing_mentions_t2.csv with 79 tweets.\n",
      "tech_reduced191218/wttj_fr_mentions_t2.csv with 3 tweets.\n",
      "tech_reduced191218/PromonetA_mentions_t2.csv with 72 tweets.\n",
      "tech_reduced191218/indica_mentions_t2.csv with 46 tweets.\n",
      "tech_reduced191218/michaelsteen_mentions_t2.csv with 47 tweets.\n",
      "tech_reduced191218/pcanfin_mentions_t2.csv with 15 tweets.\n",
      "tech_reduced191218/BorisJohnson_mentions_t2.csv with 2 tweets.\n",
      "tech_reduced191218/LIGNEP_SNCF_mentions_t2.csv with 59 tweets.\n",
      "tech_reduced191218/Le_Figaro_mentions_t2.csv with 38 tweets.\n",
      "tech_reduced191218/Rahul_J_Mathur_mentions_t2.csv with 111 tweets.\n",
      "tech_reduced191218/828AS1_mentions_t2.csv with 16 tweets.\n",
      "tech_reduced191218/gavinsblog_mentions_t2.csv with 65 tweets.\n",
      "tech_reduced191218/N_Lecaussin_mentions_t2.csv with 52 tweets.\n",
      "tech_reduced191218/abouilhet_mentions_t2.csv with 6 tweets.\n",
      "tech_reduced191218/cy_lacarriere_mentions_t2.csv with 30 tweets.\n",
      "tech_reduced191218/GDSTeam_mentions_t2.csv with 9 tweets.\n",
      "tech_reduced191218/ArianeChemin_mentions_t2.csv with 9 tweets.\n",
      "tech_reduced191218/BlancheNoire1_mentions_t2.csv with 113 tweets.\n",
      "tech_reduced191218/jshieber_mentions_t2.csv with 30 tweets.\n",
      "tech_reduced191218/vellaviens_mentions_t2.csv with 119 tweets.\n",
      "tech_reduced191218/aled_mj_mentions_t2.csv with 35 tweets.\n",
      "tech_reduced191218/chasrmartin_mentions_t2.csv with 112 tweets.\n",
      "tech_reduced191218/SamoBurja_mentions_t2.csv with 24 tweets.\n",
      "tech_reduced191218/Olivier_Auguste_mentions_t2.csv with 62 tweets.\n",
      "tech_reduced191218/NathanLatka_mentions_t2.csv with 25 tweets.\n",
      "tech_reduced191218/CaroVigoureux_mentions_t2.csv with 18 tweets.\n",
      "tech_reduced191218/Ben_Reinhardt_mentions_t2.csv with 17 tweets.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tech_reduced191218/thestartup__mentions_t2.csv with 2 tweets.\n",
      "tech_reduced191218/mattwarman_mentions_t2.csv with 25 tweets.\n",
      "tech_reduced191218/tombarfield_mentions_t2.csv with 38 tweets.\n",
      "tech_reduced191218/Mi_Weinberg_mentions_t2.csv with 37 tweets.\n",
      "tech_reduced191218/pixlpa_mentions_t2.csv with 30 tweets.\n",
      "tech_reduced191218/Republicains_An_mentions_t2.csv with 28 tweets.\n",
      "tech_reduced191218/pesasafi_mentions_t2.csv with 71 tweets.\n",
      "tech_reduced191218/gerydemaet_mentions_t2.csv with 8 tweets.\n",
      "tech_reduced191218/vgr_mentions_t2.csv with 35 tweets.\n",
      "tech_reduced191218/Conservatives_mentions_t2.csv with 35 tweets.\n",
      "tech_reduced191218/noUpside_mentions_t2.csv with 55 tweets.\n",
      "tech_reduced191218/robert19pearson_mentions_t2.csv with 62 tweets.\n",
      "tech_reduced191218/CommanderHam_mentions_t2.csv with 19 tweets.\n",
      "tech_reduced191218/founderwalkerf1_mentions_t2.csv with 15 tweets.\n",
      "tech_reduced191218/PostOpinions_mentions_t2.csv with 48 tweets.\n",
      "tech_reduced191218/robert_zubrin_mentions_t2.csv with 32 tweets.\n",
      "tech_reduced191218/pietphc_mentions_t2.csv with 9 tweets.\n",
      "tech_reduced191218/YGuichaoua_mentions_t2.csv with 17 tweets.\n",
      "tech_reduced191218/Alban_Jarry_mentions_t2.csv with 43 tweets.\n",
      "tech_reduced191218/threadascii_mentions_t2.csv with 31 tweets.\n",
      "tech_reduced191218/DCMS_mentions_t2.csv with 5 tweets.\n",
      "tech_reduced191218/jdomerchet_mentions_t2.csv with 68 tweets.\n",
      "tech_reduced191218/Siftedeu_mentions_t2.csv with 118 tweets.\n",
      "tech_reduced191218/FerghaneA_mentions_t2.csv with 31 tweets.\n",
      "tech_reduced191218/libe_mentions_t2.csv with 18 tweets.\n",
      "tech_reduced191218/sophiabendz_mentions_t2.csv with 69 tweets.\n",
      "tech_reduced191218/RossySheil_mentions_t2.csv with 8 tweets.\n",
      "tech_reduced191218/cgiorgi_mentions_t2.csv with 8 tweets.\n",
      "tech_reduced191218/kirstenkorosec_mentions_t2.csv with 13 tweets.\n",
      "tech_reduced191218/pressmium_mentions_t2.csv with 12 tweets.\n",
      "tech_reduced191218/DenisCosnard_mentions_t2.csv with 10 tweets.\n",
      "tech_reduced191218/maijapalmer_mentions_t2.csv with 43 tweets.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "edge_df = pd.DataFrame()\n",
    "for filename in glob.glob(data_path + '*_mentions' +'_t' +str(thres)+ '.csv'):\n",
    "    new_edge_df = pd.read_csv(filename)\n",
    "    print('{} with {} tweets.'.format(filename,len(new_edge_df)))\n",
    "    edge_df = edge_df.append(new_edge_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>mention</th>\n",
       "      <th>weight</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>date</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pietraszewski_l</td>\n",
       "      <td>DimPolitique</td>\n",
       "      <td>1</td>\n",
       "      <td>['RetraitePourTous', 'retraite']</td>\n",
       "      <td>['2019-12-15 08:53:27']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pietraszewski_l</td>\n",
       "      <td>F3nord</td>\n",
       "      <td>1</td>\n",
       "      <td>['RetraitePourTous', 'retraite']</td>\n",
       "      <td>['2019-12-15 08:53:27']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>pietraszewski_l</td>\n",
       "      <td>LaREM_AN</td>\n",
       "      <td>2</td>\n",
       "      <td>['RetraitePourTous', 'LeTalk']</td>\n",
       "      <td>['2019-12-16 18:58:20', '2019-12-12 14:33:11']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>pietraszewski_l</td>\n",
       "      <td>LaRemNord</td>\n",
       "      <td>1</td>\n",
       "      <td>['RetraitePourTous', 'LeTalk']</td>\n",
       "      <td>['2019-12-12 14:33:11']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>pietraszewski_l</td>\n",
       "      <td>Le_Figaro</td>\n",
       "      <td>3</td>\n",
       "      <td>['RetraitePourTous', 'LeTalk', 'LeTalk']</td>\n",
       "      <td>['2019-12-13 12:22:25', '2019-12-12 14:33:11',...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>maijapalmer</td>\n",
       "      <td>carlsberg</td>\n",
       "      <td>2</td>\n",
       "      <td>['AI', 'whisky', 'beer']</td>\n",
       "      <td>['2019-12-17 11:27:39', '2019-12-17 07:45:00']</td>\n",
       "      <td>['https://sifted.eu/articles/ai-whisky-beer/',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>maijapalmer</td>\n",
       "      <td>mackmyra</td>\n",
       "      <td>2</td>\n",
       "      <td>['AI', 'whisky', 'beer']</td>\n",
       "      <td>['2019-12-17 11:27:39', '2019-12-17 07:45:00']</td>\n",
       "      <td>['https://sifted.eu/articles/ai-whisky-beer/',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>maijapalmer</td>\n",
       "      <td>orange</td>\n",
       "      <td>1</td>\n",
       "      <td>['corporate', 'innovation']</td>\n",
       "      <td>['2019-12-17 13:32:41']</td>\n",
       "      <td>['https://sifted.eu/articles/corporate-innovat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>maijapalmer</td>\n",
       "      <td>pfizer</td>\n",
       "      <td>1</td>\n",
       "      <td>['corporate', 'innovation']</td>\n",
       "      <td>['2019-12-17 13:32:41']</td>\n",
       "      <td>['https://sifted.eu/articles/corporate-innovat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>maijapalmer</td>\n",
       "      <td>tsingtao</td>\n",
       "      <td>1</td>\n",
       "      <td>['AI', 'whisky', 'beer']</td>\n",
       "      <td>['2019-12-17 11:27:39']</td>\n",
       "      <td>['https://sifted.eu/articles/ai-whisky-beer/']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0             user       mention  weight  \\\n",
       "3            3  pietraszewski_l  DimPolitique       1   \n",
       "4            4  pietraszewski_l        F3nord       1   \n",
       "8            8  pietraszewski_l      LaREM_AN       2   \n",
       "9            9  pietraszewski_l     LaRemNord       1   \n",
       "11          11  pietraszewski_l     Le_Figaro       3   \n",
       "..         ...              ...           ...     ...   \n",
       "27          27      maijapalmer     carlsberg       2   \n",
       "35          35      maijapalmer      mackmyra       2   \n",
       "36          36      maijapalmer        orange       1   \n",
       "37          37      maijapalmer        pfizer       1   \n",
       "43          43      maijapalmer      tsingtao       1   \n",
       "\n",
       "                                    hashtags  \\\n",
       "3           ['RetraitePourTous', 'retraite']   \n",
       "4           ['RetraitePourTous', 'retraite']   \n",
       "8             ['RetraitePourTous', 'LeTalk']   \n",
       "9             ['RetraitePourTous', 'LeTalk']   \n",
       "11  ['RetraitePourTous', 'LeTalk', 'LeTalk']   \n",
       "..                                       ...   \n",
       "27                  ['AI', 'whisky', 'beer']   \n",
       "35                  ['AI', 'whisky', 'beer']   \n",
       "36               ['corporate', 'innovation']   \n",
       "37               ['corporate', 'innovation']   \n",
       "43                  ['AI', 'whisky', 'beer']   \n",
       "\n",
       "                                                 date  \\\n",
       "3                             ['2019-12-15 08:53:27']   \n",
       "4                             ['2019-12-15 08:53:27']   \n",
       "8      ['2019-12-16 18:58:20', '2019-12-12 14:33:11']   \n",
       "9                             ['2019-12-12 14:33:11']   \n",
       "11  ['2019-12-13 12:22:25', '2019-12-12 14:33:11',...   \n",
       "..                                                ...   \n",
       "27     ['2019-12-17 11:27:39', '2019-12-17 07:45:00']   \n",
       "35     ['2019-12-17 11:27:39', '2019-12-17 07:45:00']   \n",
       "36                            ['2019-12-17 13:32:41']   \n",
       "37                            ['2019-12-17 13:32:41']   \n",
       "43                            ['2019-12-17 11:27:39']   \n",
       "\n",
       "                                                 urls  \n",
       "3                                                  []  \n",
       "4                                                  []  \n",
       "8                                                  []  \n",
       "9                                                  []  \n",
       "11                                                 []  \n",
       "..                                                ...  \n",
       "27  ['https://sifted.eu/articles/ai-whisky-beer/',...  \n",
       "35  ['https://sifted.eu/articles/ai-whisky-beer/',...  \n",
       "36  ['https://sifted.eu/articles/corporate-innovat...  \n",
       "37  ['https://sifted.eu/articles/corporate-innovat...  \n",
       "43     ['https://sifted.eu/articles/ai-whisky-beer/']  \n",
       "\n",
       "[550 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display edges with number of hashtags >1\n",
    "edge_df[edge_df['hashtags'].apply(lambda x : len(x.split()))>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the graph from the edge list\n",
      "Nb of nodes: 4810\n",
      "Nb of nodes after removing less connected nodes: 717\n",
      "removed 1 isolated nodes.\n"
     ]
    }
   ],
   "source": [
    "DEGREE_MIN = 2 # Minimal number of connections in the graph\n",
    "\n",
    "G = pysad.graph_from_edgeslist(edge_df,DEGREE_MIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of partitions: 14\n"
     ]
    }
   ],
   "source": [
    "G = pysad.detect_communities(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname = 'multiusersgraph'\n",
    "#graphname = 'GBRgraph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote tech_reduced191218/multiusersgraph_t2_md2_graph.gexf\n"
     ]
    }
   ],
   "source": [
    "# Save the graph\n",
    "import networkx as nx\n",
    "\n",
    "graphfilename = data_path + graphname + '_t' + str(thres) + '_md' + str(DEGREE_MIN) +'_graph.gexf'\n",
    "nx.write_gexf(G,graphfilename)\n",
    "print('Wrote',graphfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtags, dates and urls\n",
    "Hashtags, dates and urls are on the edges of the network.\n",
    "We can get the most common hashtags within a community and also betwenn communities using the edges that connect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_dic, dates_dic, url_dic = pysad.community_data(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Community</th>\n",
       "      <th>Average date</th>\n",
       "      <th>Deviation (days)</th>\n",
       "      <th>hashtag0</th>\n",
       "      <th>hashtag1</th>\n",
       "      <th>hashtag2</th>\n",
       "      <th>hashtag3</th>\n",
       "      <th>hashtag4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>1</td>\n",
       "      <td>corporate</td>\n",
       "      <td>innovation</td>\n",
       "      <td>2020vision</td>\n",
       "      <td>2020trends</td>\n",
       "      <td>startups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>1</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>startup</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-12-15</td>\n",
       "      <td>2</td>\n",
       "      <td>retraites</td>\n",
       "      <td>Retraites</td>\n",
       "      <td>LeGrandFaceàFace</td>\n",
       "      <td>RetraitePourTous</td>\n",
       "      <td>DirectAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>2</td>\n",
       "      <td>Retraites</td>\n",
       "      <td>Sahel</td>\n",
       "      <td>retraites</td>\n",
       "      <td>retraite</td>\n",
       "      <td>Delevoye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2</td>\n",
       "      <td>FigaroLive</td>\n",
       "      <td>pointsdevue</td>\n",
       "      <td>PointsDeVue</td>\n",
       "      <td>reformedesretraites</td>\n",
       "      <td>greve17decembre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-12-15</td>\n",
       "      <td>1</td>\n",
       "      <td>ReleaseTheRussiaReport</td>\n",
       "      <td>COP26</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>GE2019</td>\n",
       "      <td>Equality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>1</td>\n",
       "      <td>Delevoye</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>1</td>\n",
       "      <td>GE2019</td>\n",
       "      <td>dataviz</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>1</td>\n",
       "      <td>EUCO</td>\n",
       "      <td>EUGreenDeal</td>\n",
       "      <td>realgreendeal</td>\n",
       "      <td>Delevoye</td>\n",
       "      <td>CQFD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2</td>\n",
       "      <td>HR</td>\n",
       "      <td>recruitment</td>\n",
       "      <td>bias</td>\n",
       "      <td>RH</td>\n",
       "      <td>stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>2</td>\n",
       "      <td>VacuousBuddhistPlatitudes</td>\n",
       "      <td>roamcult</td>\n",
       "      <td>AncientAmazons</td>\n",
       "      <td>StripeyPants</td>\n",
       "      <td>hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2</td>\n",
       "      <td>pseudoscience</td>\n",
       "      <td>ogm</td>\n",
       "      <td>netflix</td>\n",
       "      <td>GretaThunberg</td>\n",
       "      <td>greve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2019-12-18</td>\n",
       "      <td>0</td>\n",
       "      <td>LaTransformacionDeCuarta</td>\n",
       "      <td>INEPTOCRACIA</td>\n",
       "      <td>JustTheRealNews</td>\n",
       "      <td>JTRN</td>\n",
       "      <td>SAS2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2</td>\n",
       "      <td>ECBYouthDialogue</td>\n",
       "      <td>EUGreenDeal</td>\n",
       "      <td>LagardeScarfGuesses</td>\n",
       "      <td>eurozone</td>\n",
       "      <td>EuroSummit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Community Average date  Deviation (days)                   hashtag0  \\\n",
       "0           0   2019-12-14                 1                  corporate   \n",
       "1           1   2019-12-16                 1                    unicorn   \n",
       "2           2   2019-12-15                 2                  retraites   \n",
       "3           3   2019-12-16                 2                  Retraites   \n",
       "4           4   2019-12-14                 2                 FigaroLive   \n",
       "5           5   2019-12-15                 1     ReleaseTheRussiaReport   \n",
       "6           6   2019-12-16                 1                   Delevoye   \n",
       "7           7   2019-12-13                 1                     GE2019   \n",
       "8           8   2019-12-16                 1                       EUCO   \n",
       "9           9   2019-12-14                 2                         HR   \n",
       "10         10   2019-12-16                 2  VacuousBuddhistPlatitudes   \n",
       "11         11   2019-12-14                 2              pseudoscience   \n",
       "12         12   2019-12-18                 0   LaTransformacionDeCuarta   \n",
       "13         13   2019-12-14                 2           ECBYouthDialogue   \n",
       "\n",
       "        hashtag1             hashtag2             hashtag3         hashtag4  \n",
       "0     innovation           2020vision           2020trends         startups  \n",
       "1        startup                                                             \n",
       "2      Retraites     LeGrandFaceàFace     RetraitePourTous         DirectAN  \n",
       "3          Sahel            retraites             retraite         Delevoye  \n",
       "4    pointsdevue          PointsDeVue  reformedesretraites  greve17decembre  \n",
       "5          COP26              Glasgow               GE2019         Equality  \n",
       "6                                                                            \n",
       "7        dataviz                                                             \n",
       "8    EUGreenDeal        realgreendeal             Delevoye             CQFD  \n",
       "9    recruitment                 bias                   RH           stress  \n",
       "10      roamcult       AncientAmazons         StripeyPants         hashtags  \n",
       "11           ogm              netflix        GretaThunberg            greve  \n",
       "12  INEPTOCRACIA      JustTheRealNews                 JTRN          SAS2019  \n",
       "13   EUGreenDeal  LagardeScarfGuesses             eurozone       EuroSummit  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_table = pysad.communities_date_hashtags(dates_dic, tags_dic)\n",
    "community_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_table = pysad.communities_urls(url_dic)\n",
    "url_table = pysad.convert_bitly(url_table)\n",
    "filtered_url_table = pysad.drop_twitter_urls(url_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>Community</th>\n",
       "      <th>Occurence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://Bill.com</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://Europe1.fr</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://Slido.com</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://benjaminreinhardt.com/predictably-succe...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://bit.do/fkpkM</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>https://www.youtube.com/watch?v=D0uE1qi2A68</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>https://www.youtube.com/watch?v=PpNBgGu4Ahw</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>https://yiu.co.uk/blog/wanted-a-new-party-that...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>https://youtu.be/UTvy1BT1iks</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>https://youtu.be/ucuSp2QiK_I</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  Community  Occurence\n",
       "0                                      http://Bill.com          1          1\n",
       "1                                    http://Europe1.fr          3          1\n",
       "2                                     http://Slido.com         13          2\n",
       "3    http://benjaminreinhardt.com/predictably-succe...         10          1\n",
       "4                                  http://bit.do/fkpkM         13          1\n",
       "..                                                 ...        ...        ...\n",
       "422        https://www.youtube.com/watch?v=D0uE1qi2A68         13          2\n",
       "423        https://www.youtube.com/watch?v=PpNBgGu4Ahw         13          2\n",
       "424  https://yiu.co.uk/blog/wanted-a-new-party-that...          9          1\n",
       "425                       https://youtu.be/UTvy1BT1iks          8          2\n",
       "426                       https://youtu.be/ucuSp2QiK_I         13          1\n",
       "\n",
       "[427 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort users by community and save in a excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort users by community and store their node degree (importance)\n",
    "community_nodes = {}\n",
    "for node,data in G.nodes(data=True):\n",
    "    community_nb = data['community']\n",
    "    if  community_nb not in community_nodes:\n",
    "        community_nodes[community_nb] = [(node, G.degree(node))]\n",
    "    else:\n",
    "        community_nodes[community_nb].append((node, G.degree(node)))\n",
    "\n",
    "\n",
    "# Display the exmaple of community c_idx\n",
    "#c_idx = 0\n",
    "#ddf = pd.DataFrame(community_nodes[c_idx],columns=['User','Degree'])\n",
    "#print('list of most connected users in community',c_idx)\n",
    "#ddf.sort_values(by='Degree',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to an excel file\n",
    "with pd.ExcelWriter(data_path + 'graph_infos.xlsx') as writer:\n",
    "    for community_nb in community_nodes:\n",
    "        ddf = pd.DataFrame(community_nodes[community_nb],columns=['User','Degree'])\n",
    "        ddf = ddf.sort_values(by='Degree',ascending=False)#.head(20)\n",
    "        ddf.to_excel(writer, sheet_name='Community_' + str(community_nb),index=False)\n",
    "    community_table.to_excel(writer, sheet_name='Hashtags',index=False)\n",
    "    #users_df.to_excel(writer, sheet_name='Initial_users_details',index=False)\n",
    "    filtered_url_table.to_excel(writer, sheet_name='List_of_urls',index=False)\n",
    "    # Set the column width\n",
    "    column_width = 25\n",
    "    for sheet in writer.sheets: \n",
    "        worksheet = writer.sheets[sheet]\n",
    "        for col in ['A','B','C','D','E','F','G','H']:\n",
    "            worksheet.column_dimensions[col].width = column_width\n",
    "    writer.sheets['List_of_urls'].column_dimensions['A'].width = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags_dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
